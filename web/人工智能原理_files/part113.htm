<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-cn" lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>6.3.1 图表示学习</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part112.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part114.htm">下一个 &gt;</a></p><p class="s14" style="padding-left: 7pt;text-indent: 0pt;line-height: 22pt;text-align: left;"><a name="bookmark117">6.3.1 </a><span class="h4">图表示学习</span></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">图表示学习的研究对象是图数据。图数据中蕴涵着丰富的结构信 息，这本质上对应着图数据因内在关联而产生的一种非线性结构。这 种非线性结构在补充刻画数据的同时，也给数据的学习带来了极大的 挑战。因此在这样的背景下，图表示学习就显得格外重要，因为它一 方面将图数据表示成线性空间中的向量。从工程上而言，这种向量化 的表示为擅长处理线性结构数据的计算机体系提供了极大的便利。另 一方面可以为之后的学习任务奠定基础。图数据的学习任务种类繁多，有节点层面的，边层面的，还有全图层面的，一个好的图表示学习方 法可以统一高效地辅助这些任务的相关设计与学习。图表示学习从方 法上来说，可以分为基于分解的方法、基于随机游走的方法、基于深 度学习的方法等，而基于深度学习的方法的典型代表就是 <span class="s10">GNN </span>相关 的方法。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">在早期，图节点的嵌入学习一般是基于分解的方法，这些方法通过对描述图数据结构信息的矩阵进行矩阵分解，将节点转化到低维向量空间中去，同时保留结构上的相似性。这种描述结构信息的矩阵比如有邻接矩阵，拉普拉斯矩阵，节点相似度矩阵。一般来说，这类方法均有解析解，但是由于结果依赖于相关矩阵的分解计算，因此，这类方法具有很高的时间复杂度和空间复杂度。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">近些年，词向量方法在语言表示上取得了很大的成功，受该方法的启发，一些方法开始将在图中随机游走产生的序列看作句子，节点看作词，以此类比词向量从而学习出节点的表示。典型的方法比如 <a href="part329.htm#bookmark569" class="s5">Deepwalk</a><span class="s20">[50]</span><span class="s10"> </span>和 <a href="part329.htm#bookmark570" class="s5">Node2Vec</a><span class="s20">[51]</span><span class="s10"> </span>等。<span class="s10">Deepwalk </span>的方法采用了随机游走的思想进行结点采样。首先根据用户的行为构建出一个图网络，随后通过随机游走随机采样的方式构建出结点序列，随后将得到的路径序</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: justify;">列作为输入，使用词嵌入领域常用的 <span class="s10">Skip-Gram </span>模型得到每个结点的向量表示。基于随机游走的方法相比上一类方法，最大的优点是通过将图转化为序列的方式从而实现了大规模图的表示学习。但是这也导致了两个缺点：一是将图转化成序列集合，图本身的结构信息没有被充分利用；二是该学习框架很难自然地融合进图中的属性信息进行表示学习。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">关于 <span class="s10">GNN </span>方法非常自然地融合进了图的属性信息进行学习，而 之前的方法大多把图里面的结构信息与属性信息进行单独处理。 <span class="s10">GNN  </span>本身作为一个可导的模块，能够嵌入到任意一个支持端对端学 习的系统中去，这种特性使得其能够与各个层面的有监督学习任务进 行有机结合（或者以微调学习的形式进行结合），学习出更加适应该 任务的数据表示。<span class="s10">GNN </span>的很多模型如 <span class="s10">GraphSAGE</span>、<span class="s10">MPNN </span>等都是支 持归纳学习的，多数情况下对于新数据的表示学习可以直接进行预测，而不用像之前的多数方法需要重新训练一次。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">图表示学习可用来做链接预测，在不同领域中都有广泛的应用。在社交网络中，图表示学习可以用于预测两个用户之间是否存在社交关系。这对于社交推荐、社交影响力分析、社区发现等任务非常重要。在推荐系统中，图表示学习可以用于预测用户与物品之间的连接，例如预测用户是否喜欢某个商品或电影。通过建模用户和物品之间的关系，可以提高推荐精度。在生物信息学研究中常常需要预测蛋白质<span class="s10">-</span>蛋白质相互作用、药物<span class="s10">-</span>蛋白质关联等。图表示学习可以用于学习蛋白质和药物分子的特征表示，以预测它们之间的关联性。在金融领域，图表示学习可以用于预测用户之间的金融交易关系，检测欺诈行为，发现风险传播路径等。这对于风险控制和反洗钱等具有重要意义。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">图表示学习是一个活跃的研究领域，未来的发展方向有以下几个：第一，处理大规模图数据的方法研究，设计高效的算法和技术，以便 能够更好地处理大型复杂网络，加速计算过程并保持表示的质量。第</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: left;">二，开发可解释性强的图表示学习方法，使得学到的表示能够被解释为具有实际含义的特征，提高模型的可解释性和可靠性。最后，推动图表示学习与其他领域的交叉应用，如与自然语言处理、计算机视觉、生物医药等领域相结合，拓展图表示学习在更多领域中的应用。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">综上所述，图表示学习作为一种重要的机器学习技术，可以有效地处理图结构数据，具有广泛的应用前景。随着研究的深入和技术的发展，图表示学习将在各个领域中起到更加重要的作用。</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part112.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part114.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
