<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-cn" lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>6.1.2 前馈神经网络</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part105.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part107.htm">下一个 &gt;</a></p><p class="s14" style="padding-left: 7pt;text-indent: 0pt;line-height: 22pt;text-align: left;"><a name="bookmark108">6.1.2 </a><span class="h4">前馈神经网络</span></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">前馈神经网络（<span class="s10">Feedforward Neural Network</span>）是最基本和常见的神经网络类型之一。该类神经网络一般由三大结构组成：输入层、隐藏层和输出层。其中输入层是网络的起点，它接收原始数据作为输入；输出层是位于网络最后的一层，用于输出后续可应用于各种场景的结果；隐藏层则是位于输入层和输出层之间的中间层，它可以由一个或多个层组成。这些层中的每一层都包含多个神经元，每个神经元都将来自上一层的输入进行加权并求和，并通过一个激活函数进行非线性转换。前馈神经网络的原理在于将输入数据通过一系列带有非线性转换的运算层来拟合现实世界中复杂的函数以预测各种任务场景下的结果。</p><p class="s10" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">6.1.2.1 <span class="s37">多层感知机与全连接神经网络</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">在该类神经网络中，每一层中的每个神经元都与上一层的所有神经元相连，符合这种结构的神经网络又被称全连接网络。多层感知机</p><p class="s20" style="padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: left;">[14]<a href="part329.htm#bookmark550" class="s5"> </a>-[15]<span class="s10"> </span><span class="p">是一种最基本的全连接网络，其输入层一般负责接收数据样 本的属性作为输入数据。相邻层之间相连的神经元可用有向箭头（从 输入层指向输出层方向）连接并且可以带有权重。在输入向输出层逐 层传递的过程中，每个神经元都结合上一层的神经元的输出和两者之 间的连接权重做加权求和，计算本神经元的输出结果并向下一层的神 经元传递。值得注意的是，由于加权求和的线性，多个隐藏层本质上 等同于一个隐藏层，这将导致神经网络拟合真实函数的能力十分有限。因此，在隐藏层和输出层的神经元中往往还配有激活函数以引入非线 性，借此提高模型拟合真实函数的能力。这样，神经元在计算完加权 求和的结果后，先将结果送入激活函数，激活函数的输出才会作为下 一层神经元的输入。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">整个多层感知机的计算原理便是输入数据通过一系列带有非线性转换的运算层来拟合现实世界中复杂的函数，后续可用于各种现实场景下的任务，尤其是预测类的任务。</p><p class="s10" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">6.1.2.2 <span class="s37">卷积神经网络</span></p><p class="s10" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;"><a href="part329.htm#bookmark551" class="a">卷积神经网络</a><a href="part329.htm#bookmark551" class="s33">[16</a><span class="s20">]</span><a href="part329.htm#bookmark552" class="s5">   </a><a href="part329.htm#bookmark552" class="s33">-[19</a><span class="s20">]</span>   <span class="p">的核心思想在于模仿人类实现对图片的局 部或全局感知，使计算机对于图片的感知级别由像素级别上升到局部 或全局级别，这意味着让网络一次性感知多个像素，而非一个个对像 素进行处理。在卷积神经网络中，感知多个像素的操作称为卷积或互 相关运算，该操作主要由卷积核和图片输入来共同完成。具体来说，卷积核是一个有着固定长度和宽度的矩阵，它从图片的左上角开始，对一定区域内的像素值构成的矩阵进行按位置相乘并求和的运算，之 后按照从左到右、从上到下的顺序移动固定个像素值（步幅），之后 重复进行运算、按序移动等过程直至卷积核无法在当前图片上再进行 移动。通常情况下，经过卷积运算后的输出图像与输入图像相比会变 小，可以将其理解为提取了原始图像局部特征之后的形成的更高层级 的新图像，这些局部特征可能是边缘、纹理等等，且计算机对这些特 征是敏感的。卷积核即为卷积神经网络可训练、学习的部分，一般情 况下，其长度与宽度相等且该值是网络的一个超参数。在卷积运算过 程中，有另外两个重要的操作值得一提：步幅和填充。步幅（</span>Stride<span class="p">） 即卷积神经网络中卷积核在输入图片上进行移动时以像素值个数为 单位的移动距离，进一步可分为水平步幅和垂直步幅，分别对应卷积 核在图片上由左向右、右上到下每次移动多少个像素；填充（</span>Padding<span class="p">）操作则是指在原始输入图片的上下左右四侧填充 </span>0 <span class="p">像素值的操作。在 某些情况下，可能会希望输出图像的大小与输入图像相等而不是变小，或者是指定输出图像的大小，这一目的便可以通过对输入图片进行填 充达成。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">6.1.2.3 <span class="s37">池化方法</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">与卷积层类似，池化层上进行的池化运算也是通过一个能够滑动的窗口（池化窗口）来实现的，该窗口根据特定的步幅在输入的所有区域上从左到右、从上到下地移动，并为每个遍历的位置计算一个输出。与卷积层不同的是，池化运算是确定的，即池化层没有可训练的参数。常用的池化运算为最大值池化或平均值池化，对应的池化层被称为最大池化层或平均池化层，分别进行对池化窗口内的二维张量进行求最大值或求平均值操作。通过池化操作，特征图的尺寸能够显著减小，进而可以减少卷积神经网络的计算量，并使模型具有一定的平移不变性和鲁棒性。</p><p class="s10" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">6.1.2.4 <span class="s37">自编码器</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">前 馈 神 经 网 络的 自 编 码 器 （ <span class="s10">Feedforward Neural Network Autoencoder</span>）是一种无监督学习模型，用于将输入数据压缩为低维表示并进行重建。自编码器主要由两部分组成：编码器和解码器。编码器将输入数据映射到一个较低维度的隐藏层表示，这个隐藏层可以看作是对输入数据的压缩表示。解码器则将隐藏层的表示重新映射回原始输入空间，以重建输入数据。</p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">自编码器的训练过程包括两个阶段：</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">1</span>）编码阶段：在编码阶段，将输入数据通过编码器进行映射，得到隐藏层的表示；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">2</span>）解码阶段：在解码阶段，将隐藏层的表示通过解码器进行映射，以重建输入数据。目标是使重建的数据与原始输入数据尽可能接近，即最小化重建误差。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">自编码器的一个关键点是隐藏层的维度比输入层的维度低，这迫使自编码器学习数据中的主要特征，并丢弃输入数据中的噪声或不重要的信息。通过这种压缩和重建的过程，自编码器可以学习到一个更紧凑和鲁棒的表示。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">自编码器可以用于降维、特征提取、数据去噪等任务。它也可以 作为其他更复杂神经网络模型的组件，用于初始化权重或进行预训练。需要注意的是，自编码器是一种无监督学习方法，不需要标签信息进 行训练。然而，在一些情况下，也可以将自编码器与有监督学习结合， 例如，将自编码器的隐藏层作为输入传递给一个有监督分类器，以利 用自编码器学得的特征进行监督学习任务。</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part105.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part107.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
