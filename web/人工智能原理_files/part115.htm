<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-cn" lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>6.3.3 图神经网络前沿</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part114.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part116.htm">下一个 &gt;</a></p><p class="s14" style="padding-left: 7pt;text-indent: 0pt;line-height: 22pt;text-align: left;"><a name="bookmark119">6.3.3 </a><span class="h4">图神经网络前沿</span></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;">近几年来，图数据分析和图神经网络迅速发展，由此产生了诸多新的问题。本节主要包括复杂图的图神经网络、图神经网络认知与推理、图自监督学习和图深度生成这四个部分。</p><p class="s10" style="padding-left: 7pt;text-indent: 0pt;line-height: 18pt;text-align: left;">6.3.3.1 <span class="s37">面向复杂图的图神经网络</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">复杂图神经网络是一种针对复杂结构图数据设计的深度学习模型，它能够提取更丰富的特征表示进行节点分类、链接预测、图分类、图生成等任务。该网络通常由多个图卷积层或图注意力层的组合来增强节点和图的表达能力，因此能够处理包括动态图和特殊结构（如异</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: justify;">配图、有向图、超图和富文本图）在内的复杂情况。复杂图神经网络为研究者理解和挖掘复杂图数据中的关系和模式提供了强大的工具和方法。</p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">1.<span class="p">异配图</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">在图神经网络的研究发展的初期，研究重心主要在处理同配图数据。同配图是指节点属性和图拓扑的耦合关系满足同配假设的一类图数据。同配假设表示相邻节点倾向于有相同的类别，因此能涵盖大多数的引文网络和社交网络等网络数据。图同质性的度量方法是综合所有节点的同配率，其中节点的同配率是通过计算其邻居节点中同类节点的比例得到。图的同配率越高，图中节点的同类邻居比例越大，通常该类型的图被称为同配图。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">异配图是指同配率较低的图数据，图中节点与其相邻节点属于不同类别的比例较高。真实场景中存在大量的此类异配网络，如婚恋网络与单词网络等网络数据。传统的基于同配假设的图神经网络模型</p><p style="padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: left;">（如图卷积网络 <a href="part329.htm#bookmark571" class="s5">GCN</a><span class="s20">[52]</span><span class="s10"> </span>和图注意力网络 <a href="part329.htm#bookmark572" class="s5">GAT</a><span class="s20">[53]</span><span class="s10"> </span>）无法直接为此类图数据提供解决方案，因此需要设计新的模型来满足这一需求。处理此类数据需要模型包含能够区分节点间关系的附加参数化网络模块，突破经典模型中对图数据的同配归纳偏置。</p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">针对图神经网络在异配图上的改进主要聚焦于以下三个方向：</p><p class="s10" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><span class="p">（</span>1<a href="part329.htm#bookmark573" class="a">）多样化的传播机制：在保持现有拓扑邻居的基础上探索更加适应性强的传播机制。一种方案是在图注意力网络中引入实值传播权重，以实现特征传播在平滑和锐化之间的平衡</a><span class="s20">[54]</span> <span class="p">；另一种方案是通过构建特征通道的传播权重，以实现特征级别的细粒度特征传播</span></p><p class="s20" style="padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: justify;">[55]<span class="s10"> </span><a href="part329.htm#bookmark575" class="a">；另一种方案是利用伪标签推断随机块来评估节点对的异配程度，以实现监督性更强的特征传播</a>[56]<span class="s10"> </span><span class="p">。</span></p><p class="s10" style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;"><span class="p">（</span>2<a href="part329.htm#bookmark576" class="a">）非局部邻居的提取：挖掘非局部邻域的特征信息以补充局 部信息量的欠缺。一种方案是组合高阶特征来引入高阶邻居信息</a><span class="s20">[57]</span> <span class="p">，</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: justify;"><a href="part329.htm#bookmark577" class="a">改进图神经网络在异配图处理中的特征传播效果；另一种方案是分别在特征空间和双曲空间构建网络并执行特征传播</a>[59]<span class="s10"> </span><span class="p">。</span></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">3</span>）多样化的图数据建模：设计非图卷积的方案来挖掘图信息。主要的方案是利用机器学习模块（如多层感知机）分别编码属性和拓<a href="part329.htm#bookmark578" style=" color: black; font-family:仿宋, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; vertical-align: -5pt;">扑结构</a><a href="part329.htm#bookmark578" class="s34">[61</a><span class="s22">]    </span><span class="s21">。</span></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">图异配问题的解决对于各种图学习任务而言具有重要的意义。在图分类任务中，解决该问题有助于通过局部信息推断出节点的全局类别，从而增强标签传播能力并提升图结构的判别力，从而显著提高图分类算法的准确度。在社交网络分析中，解决图异配问题可以改善社交网络分析的效果，提高社区发现和关系预测的准确性。在信息传播和推荐系统领域，解决图异配问题可以提升信息传播和推荐系统的准确性，为用户提供更加个性化和精准的推荐。未来的研究方向是在解决图异配问题时考虑节点属性信息和网络拓扑结构之间的复杂关联。</p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">2.<span class="p">富文本图</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">富文本图神经网络（<span class="s10">Text-Rich Graph Neural Network</span>）是一种结 合了富文本和图神经网络的方法，用于处理带有文本信息的图结构数 据。传统的图神经网络主要关注节点和边之间的拓扑结构和连接关系，而在现实世界中，图结构中通常伴随着大量的文本信息，这些文本信 息能够提供更丰富的语义和上下文信息。因此，为了处理这种带有文 本信息的图数据，富文本图神经网络应运而生。</p><p class="s20" style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;"><a href="part329.htm#bookmark579" class="a">富文本图神经网络的核心思想是融合图结构和文本信息进行联合学习。在具体实现中，通常包括以下几个步骤</a>[62]<span class="s10"> </span><span class="p">：</span></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">1</span>）网络构建：将图结构数据转化为机器学习可处理的形式，同时保留节点之间的连接关系和文本描述信息。可以使用邻接矩阵或邻接表来表示图的结构，同时将文本信息表示为词向量或句向量；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;">（<span class="s10">2</span>）节点特征提取：对于每个节点，将其文本描述信息转化为向量表示。可以使用预训练的语言模型（如 <span class="s10">BERT</span>、<span class="s10">GPT </span>等）来提取</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">文本特征，得到节点的语义向量表示；</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">3</span>）表示学习：利用图神经网络对图结构和节点特征进行联合学习。图神经网络通过迭代地更新节点的表示，将节点的邻居节点信息和节点特征信息进行聚合，从而得到更丰富的节点表达；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">4</span>）任务建模：基于学习到的节点表示，可以进行各种任务建模，如节点分类、链接预测、关系抽取等。可以使用传统的机器学习方法或深度学习方法进行任务建模和预测。</p><p class="s20" style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;"><a href="part329.htm#bookmark580" class="a">富文本图神经网络</a>[64]<span class="s10"> </span><span class="p">在社交媒体分析中可以应用于多个任务和场景：</span></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">1</span>）情感分析：社交媒体上的用户评论、推文等富文本数据中蕴含着丰富的情感信息；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">2</span>）构建用户之间的关系图：并结合文本内容进行节点表示的学习，从而识别和分析用户的情感倾向。该方法可以用于判断评论的积极或消极情感，帮助企业和机构了解用户对产品或服务的反馈，以做出相应的决策；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">3</span>）话题检测和趋势预测：社交媒体平台上存在大量关于不同话题的富文本数据。通过构建话题之间的关系图，利用富文本图神经网络可以对话题进行检测和分类。进一步，可以使用时间序列数据来捕捉话题的演化趋势，并进行趋势预测。该方法有助于发现热门话题、追踪话题的变化并了解用户兴趣的变化，为品牌营销和舆情监测提供支持；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">4</span>）社交网络垃圾信息检测，社交媒体平台上存在大量的垃圾 信息，如垃圾评论、虚假新闻等。使用富文本图神经网络可以构建用 户和内容之间的关系图，并通过学习节点表示来识别和过滤垃圾信息。利用图神经网络可以捕捉垃圾信息传播的模式，提高垃圾信息检测的 准确性和效率。</p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">3.<span class="p">异质信息图</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 3pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><span class="p">异质信息图是指包含多类型节点和关系的图数据，其含有丰富的结构和语义信息，有助于探索网络的隐含模式。在面向异质图的各类数据挖掘问题中，根据领域知识预定义的概念得到了广泛的应用，例如元路径（</span>Meta-Path<span class="p">），图模式（</span>Schema<span class="p">）和 </span>Motif <a href="part329.htm#bookmark581" class="a">等。其中，元路径由特定的节点类型序列和相应的边类型序列组成。它能够指定节点连接序列来获取目标语义并且具有实施简单性，因而在该领域研究中最为常用。利用元路径的异质图神经网络模型常与注意力机制结合起来，依此来获得更全面和灵活的模型</a><a href="part329.htm#bookmark581" class="s33">[65</a><span class="s20">]</span>   <span class="p">。通过在元路径上引入注意力机制，可以根据节点之间的关联和上下文动态地调整权重，实现对不同节点的精细化建模和信息聚合。</span></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">异质图数据中的属性缺失问题是指数据中存在某些类的节点缺失全部属性。在经典的异质图神经网络模型中，通常通过计算特定类别的邻居节点的平均值来为缺失属性节点生成初始表征，这在一定程度上限制了异质图模型在各类下有任务中的表现。针对这个问题，一种有效的策略是基于图数据的特性利用图注意力机制的属性补全。它利用图神经网络对特征的重构能力，通过加权组合局部邻居的特征来重构缺失属性，进而缓解异质图中初始特征的表达能力不足的问题</p><p class="s20" style="padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: justify;">[68]<span class="s10"> </span><span class="p">。解决异质图数据的属性缺失问题对于提高数据完整性、优化预测和分类效果、增强特征表征能力以及推动关系挖掘和网络分析等方面具有重要意义。</span></p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">异质图数据的多类型和多关系性质给数据的表征带来挑战。</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">1</span>）处理大规模异质图数据需要高效的存储和计算技术，并解决数据稀疏性和维度灾难等问题；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">2</span>）建模过程需要合理处理不同类型的节点和边，并捕捉到异质图中的复杂模式和潜在关联。综合利用图算法、深度学习和知识表示等技术来处理和建模异质图数据，将有助于解决复杂问题并推动各领域的研究应用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 3pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">4.<span class="p">时空图</span></p><p class="s10" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;"><span class="p">时空图神经网络（</span>Spatio-Temporal Graph Neural Network<a href="part329.htm#bookmark583" class="a">）是一种针对时空数据建模和分析的方法</a><span class="s20">[69]</span> <span class="p">。时空数据中具有时序关系的节点和边在现实世界中广泛存在，如社交网络、交通网络、物联网等。传统的图神经网络主要处理静态图数据，忽略了时序信息和节点之间的高阶交互关系。高阶交互图神经网络（</span>Higher-Order Interaction Graph Neural Network<a href="part329.htm#bookmark584" class="a">）</a><span class="s20">[70]</span> <span class="p">是在时空图神经网络的基础上，进一步考虑节点之间的高阶交互关系而发展起来的。</span></p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">高阶交互图神经网络具体实现中，包括以下几个关键步骤：</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">1</span>）建模时间维度：引入时间维度，将时空数据划分为不同的时间片段。可以使用滑动窗口的方式将连续的时间序列切分成离散的时间片段；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;">（<span class="s10">2</span>）定义高阶交互关系：通过考虑节点在不同时间片段上的邻居节点，定义节点之间的高阶交互关系。可以采用多步邻居聚合的方式，迭代地更新节点表示，捕捉节点之间的高阶交互信息；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">3</span>）时空上下文融合：将时间信息和空间信息进行融合，得到综合的节点表示。可以采用门控机制（如 <span class="s10">LSTM</span>、<span class="s10">GRU</span>）来融合时空上下文信息；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;">（<span class="s10">4</span>）任务建模：基于学习到的节点表示，进行各种任务建模，如节点分类、动态链接预测、行为预测等。可以使用传统的机器学习方法或深度学习方法进行任务建模和预测。</p><p class="s20" style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><a href="part329.htm#bookmark585" class="a">高阶交互图神经网络</a>[71]<span class="s10"> </span><span class="p">在交通预测、动态链接预测等方面都具有广泛的应用。</span></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">1</span>）交通预测：交通网络数据可以被表示为一个图结构，其中节点表示路段或交叉口，边表示它们之间的连接关系。每个节点上可以包含多个特征，如历史交通流量、道路属性、时间信息等。这些特征可以用于构建初始节点特征向量。表示向量可以被用于预测未来某</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">一时刻的交通流量、拥堵程度等；</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">2</span>）动态链接预测：动态链接预测的输入数据是一个含有时间信息的图结构，其中节点表示对象（如用户、物品等），边表示它们之间的链接关系。每个节点上可以包含多个特征，如属性、历史行为等。这些特征可以用于构建初始节点特征向量。通过对节点之间的表示进行比较和分析，可以预测新的链接的形成或原有链接的解除。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">高阶交互图神经网络仍然是一个活跃的研究领域，存在着一些挑战和发展方向：</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">1</span>）动态图结构建模：在动态图结构上进行更准确、高效的节点表示学习，提高对时空数据的建模能力；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: left;">（<span class="s10">2</span>）自适应邻居聚合：设计更灵活、自适应的邻居聚合机制，针对不同节点和时间片段，自动调整邻居节点的权重；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">3</span>）多任务联合学习：将多个相关任务进行联合学习，共享模型参数，提高模型的泛化能力和效率；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">4</span>）可解释性研究：研究如何解释和可视化高阶交互图神经网络的结果，使得模型的决策过程更加透明和可理解。</p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">5.<span class="p">超图</span></p><p class="s20" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><a href="part329.htm#bookmark584" class="a">超图作为一类具有复杂结构的图数据，其提出和使用有利于突破对传统单关系图模型的限制，更好地满足复杂关系模式的需求。超图神经网络结合了多种成熟的机制来表征此类图数据，其中最基本的操作就是超边建模策略。它将超边信息与节点信息结合起来，通过学习超边的表示，并在超边上进行特征的传播和聚合。另外一种策略是结合注意力机制</a>[70]<span class="s10"> </span><a href="part329.htm#bookmark585" class="a">。使用注意力机制来对节点和超边进行加权，以便更好地捕捉重要的节点和超边信息。注意力机制使得模型能够针对不同的关系和上下文进行自适应学习和处理。第三种常用的策略是结合自编码器</a>[71]<span class="s10"> </span><span class="p">。超图神经网络利用自编码器的结构来学习节点和超边的低维表示，以降低维度并提高表示的表达能力。自编码器可以通过</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">重构损失或正则化项来保持信息的完整性和一致性。</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">超图具有建模复杂关系的优势，因此它被广泛用于社交网络分析、生物信息学和自然语言处理等领域。在社交网络中，它能够更准确地 表示家人、朋友、兴趣群体等多重关系，进而为研究者提供更坚实的 网络分析基础。在生物信息学研究中，它可以高效的表示复杂的生物 分子间的相互作用关系，从而帮助研究者理解生物系统的结构和功能。在自然语言处理中，它可以用于构建语义图模型，建模句子或文本中 的单词和实体之间的关系，进而帮助机器理解语义结构并进行语义推 理。</p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">超图神经网络在应用过程中存在许多的问题和挑战：</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: left;">（<span class="s10">1</span>）数据的稀疏性。超图节点和超边的稀疏会使学习和推理过程变得困难，导致模型的性能下降等问题；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;">（<span class="s10">2</span>）表征的低效性。构建超边的特征向量需要考虑其内部节点的交互以及与其他超边之间的关系，因此如何高效地表征超边仍然是一个挑战；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">3</span>）缺乏可解释性。超图中关系和结构的复杂性更高，因此其模型的解释性也是主要的挑战之一；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">4</span>）较差的可拓展性。如何高效地处理规模较大的超图来满足更为高规模的需求，即超图的可拓展性，仍然是一个重要的挑战。</p><p class="s10" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">6.3.3.2 <span class="s37">图神经网络认知与推理</span></p><p style="padding-top: 6pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">图神经网络认知与推理旨在图网络上利用深度学习技术对节点间的信息传递、转换或聚合进行建模，实现图结构的语义表示与推理计算。认知理论认为人的认知系统包含直觉系统和推理系统，而在图机器学习领域中，针对于关系推断中的预测任务，有两套不同的学习框架分别与直觉系统和推理系统相对应。其中，直觉系统（即认知系统）通过图表示学习技术将深度学习用于图数据结构，逻辑分析系统</p><p style="padding-left: 7pt;text-indent: 0pt;text-align: left;">（即推理系统）则对应于较为传统的统计关系学习，指的是将概率图</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">模型与知识、逻辑相结合的一系列方法。</p><p class="s10" style="padding-top: 7pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">1.<span class="p">认知图神经网络</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">认识图神经网络即直觉系统，主要负责快速、无意识、非语言的认知，这是目前深度学习主要做的事情。人工智能已经在直觉系统感知智能领域达到或超越了人类水准，但在需要外部知识、逻辑推理或者领域迁移的认知智能领域还处于初级阶段。目前重要的内容是图神经网络与概率图模型和马尔科夫随机场结合。概率图模型则是一种通用化的不确定性知识表示和处理方法，主要涵盖了贝叶斯网络、隐马尔科夫模型、马尔科夫决策过程等。而马尔科夫随机场（ <span class="s10">Markov Random Fields</span>，<span class="s10">MRFs</span>）是一种典型的马尔科夫网（<span class="s10">Markov Networks</span>）使用无向边来表达变量间的依赖关系。是具有马尔科夫属性的随机变量的集合，也是一种无向图形模型，其中节点对应变量，无向边表示独立性。此外，认知图神经网络中的学习范式——知识图谱嵌入也是目前主要的研究方向。知识图谱是一个符号模型，想要和现在流行的神经网络等神经模型结合起来则需要通过图表示学习得到实体和关系的向量表示，通常称为知识图谱嵌入（<span class="s10">Knowledge Graph Embedding</span>， <span class="s10">KGE</span>）。即知识图谱嵌入是将实体和关系投影到一个连续的低维空间中，使用到的技术主要有两种：融合事实信息的 <span class="s10">KGE </span>和融合附加信息的 <span class="s10">KGE</span>。特别是以 <span class="s10">Transe </span>为代表的融合事实信息知识图谱嵌入，以及使用大型知识图谱增强其他应用，如推荐系统、情感分析等。</p><p class="s10" style="padding-top: 1pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">2.<span class="p">图神经网络推理</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">推理系统，是有意识的、带逻辑、规划、推理以及可以语言表达的系统，是较慢的思考过程。在图机器学习的关系推断领域中，推理关系与逻辑表示以一阶谓词逻辑为主，用以紧凑表达领域知识和有效处理逻辑问题。此外，推理问题通常通过将有向图转换为另一种类型的图形模型来解决：马尔科夫随机场或因子图（<span class="s10">Factor Graphs</span>）。后有演变出几种重要分支：条件随机场和马尔科夫逻辑网等。条件随机场</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: justify;">（<span class="s10">Condition Random Fields</span>，<span class="s10">CRFs</span>）是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型（即判别模型），其特点是假设输出随机变量构成马尔科夫随机场。因此其常用于标注或分析序列资料，如自然语言文字或是生物序列。马尔科夫逻辑网（<span class="s10">Markov Logic Networks</span>，<span class="s10">MLMs</span>）是将马尔科夫网与一阶逻辑相结合的一种全新的统计关系学习模型。一阶谓词逻辑本身可以进行推理，但这种推理过于严谨，而马尔科夫逻辑网将这种硬性约束转化为软性约束，给出一件事为真的概率而非直接判断它的对错。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">图神经网络认知与推理相结合衍生了诸多应用方向，例如认知图谱等。认知图谱是基于原始文本数据，针对特定问题情境，使用强大的机器学习模型动态构建的，节点带有上下文语义信息的知识图谱。认知图谱的应用框架遵循认知心理学中的“双过程理论”，认知系统负责经验性的直觉判断，这一黑盒过程提取重要信息，并动态构建认知图谱<span class="s10">;  </span>推理系统则在图上进行关系推理，由于认知图谱保留了实体节点上语义信息的隐表示，所以在符号逻辑之外，亦对图神经网络等深度学习模型有增益。从而进一步做知识的表示和知识的推理，建立可解释、健壮性的人工智能理论和方法。</p><p class="s10" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">6.3.3.3 <span class="s37">图自监督学习</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">当处理大规模数据时，获取标记（带有标签）的训练数据通常是 一项昂贵且繁琐的任务。无监督学习从未标记的数据中获取潜在的模 式和结构，降低数据获取和处理的成本，为<span class="s10">&quot;</span>难以获取标签<span class="s10">&quot;</span>问题提供 了解决方案。自监督学习利用未标记的数据自动生成“伪标签”，模 型预测可以通过预测这些“伪标签”进行训练，因此自监督学习可以 被看作是一种特殊的无监督学习。图自监督学习研究主要包括生成式、预测式、对比式三类。同时，为了从本质上解释自监督学习的学习能 力并且理清各关键模块的作用，经典的自监督模型与图的关系理论也 是研究的热点。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 3pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">1.<span class="p">生成式</span></p><p class="s20" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;"><a href="part329.htm#bookmark586" class="a">基于生成机制的自监督模型利用输入数据作为监督信号来指导模型生成输出。在图数据处理中，基于图生成（即图重构）的自监督模型常通过代理解码器恢复原始特征来获取重构信息。根据图重构的对象可见其分为属性重构</a>[72]<span class="s10"> </span><a href="part329.htm#bookmark587" class="a">和结构重构</a>[74]<span class="s10"> </span><span class="p">两类。属性重构是指通过对已有数据的分析和处理，重建数据的特征属性的过程。此方案有助于选择区分度较大的特征、特征降噪、提升特征的解释性等优势；结构重构是具备拓扑结构的图数据特有的方案，它通过重建图的结构信息来帮助模型发现图中的隐藏模式、抵抗结构扰动等。</span></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">图生成式自监督学习使用“掩码预测”策略，它主要包括图样本 构造、掩码生成、模型预测和反馈信号四个步骤。具体来说，针对一 个图级别的任务，图样本构造是从未标记的图数据集中选择输入图；掩码生成为输入图屏蔽部分图的信息，即掩码。其中掩码的对象包括 节点、子图或者定义的结构；模型预测利用掩码的输入图来预测被掩 码的信息，以期学习到图的内在规律；反馈信号是计算模型预测与真 实信息之间的差异并更新模型参数的过程，以使模型的具备泛化能力。</p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">2.<span class="p">预测式</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">受监督学习的启发，基于预测机制的图自监督学习的基本思想是通过提取图数据的固有特性来建立节点伪标签，将无监督学习转换为依靠图结构数据自身信息的监督学习。根据伪标签的来源是否是显式的图数据特征，可将基于预测机制的图自监督学习可以分为性质预测</p><p class="s22" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">[75] <a href="part329.htm#bookmark589" style=" color: black; font-family:仿宋, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; vertical-align: -5pt;">和自训练</a>[76] <span class="s21">两类。</span></p><p class="s20" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;"><a href="part329.htm#bookmark590" class="a">性质预测的基本思想是预测统计属性、涉及领域知识的属性和拓扑属性等非显式的图数据特征</a>[77]<span class="s10"> </span><span class="p">。相较于图生成式的自监督学习，性质预测主要关注于预测体现图数据内在特征的自然属性，例如边的类型、基序和子图的拓扑结构等。通过预测复杂网络结构和节点之间的关系，模型可以发现图结构中隐藏的模式和规律，进而推断出这些</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: left;">隐藏信息。这种方法可以帮助研究者深入理解和研究图数据的特点和动态性质。</p><p class="s20" style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><a href="part329.htm#bookmark591" class="a">除在整个流程中设置固定变量作为伪标签外，自训练的伪标签通常是从一小批标记数据中或者从随机初始化的前一阶段的预测中获得</a>[78]<span class="s10"> </span><span class="p">。它通过预训练原始数据为未标记数据生成标签或者结构，并将生成的伪信息与原有信息进行合并，最后使用合并数据对模型进行再训练直至误差收敛。自训练方式使模型可以逐步优化自身，来逐渐提高在图表示学习任务中的性能。此外自训练更充分地利用了模型生成的伪标签或结构信息，增强了模型的泛化能力。</span></p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">3.<span class="p">对比式</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">此类方法通过对齐类别不变分布的和均匀化跨类别分布来生成样本不变性表征。具体地，它最大化正样本对之间的互信息来获取同类分布中的不变性特征，和最小化负样本对之间的互信息来防止模型塌缩。当前主流的对比学习研究主要在节点维度和特征维度上开展，因此可将基于对比机制的图自监督模型分为节点级别的对比机制和基于特征级别的对比机制两类。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">节点级别的对比机制旨在从显式设置的正负节点对的对比中获取节点表征。这种对比机制通常包括以下几个步骤：正负样本构建、表示学习、相似性度量和对比损失计算。具体来说，正负样本构建模块大多基于专家经验，例如借助同配性假设从邻居节点中采样节点作为正样本，从不相邻节点中随机选择部分节点作为负样本<span class="s20">[81-83]</span>；表示学习是指使用图神经网络（如图卷积网络 <span class="s10">GCN</span>、图注意力网络 <span class="s10">GAT</span>等）为节点生成低维表征的过程。相似性度量利用指定的相似性度量函数（如余弦相似度、距离函数等）计算节点表示之间的相似度；对比损失计算利用上述选定的正负样本和获得的相似度来计算对比损失（如对比预测损失、对比交叉熵损失等），进而优化模型参数完成对比学习。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">节点级别对比学习机制发展的初期，大多数模型遵循为拓扑上下文节点生成相似的低维节点表征思想。为了解决上述方法的拓扑局限问题，属性图上常用的方法是利用图增广策略为同一数据生成不同视角的观察，依此来获取更丰富的底层语义信息。常见的图增广方式包括属性增广、拓扑增广、局部结构的变化、特征空间变换等。属性增广常对节点属性添加噪声，拓扑增广常删除或者增加边，局部结构变化常扰动局部邻域，特征空间变换常变换或重组节点特征。对于不同的具体任务和数据集，不存在某种增广方式或者组合能够适用于所有情况。因此，当前在应用图增广时仍需要根据任务和数据集的特点选择适合的方式，并结合交叉验证等技术进行参数调整和评估，以提高模型的泛化性能和稳定性。</p><p class="s10" style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><a href="part329.htm#bookmark592" class="a">上述方法均涉及精心设计的正负样本提取方案，然而其依赖领域知识的方式存在灵活性不足和对数据变化敏感的问题。特征级别的对比机制解决了此问题，并且通过调整特征维度来平衡计算复杂度和空间复杂度。一种有效的方案是采用跨视角的软去相关策略，以最大程度地增强两个视角上相同特征的互信息，并最小化跨特征之间的互信息，进而防止模型塌缩现象</a><a href="part329.htm#bookmark592" class="s33">[84</a><span class="s20">]</span><a href="part329.htm#bookmark593" class="s5">   </a><a href="part329.htm#bookmark593" class="s33">-[85</a><span class="s20">]</span>   <span class="p">。另一种方案是结合典型相关分析（</span>Canonical Correlation Analysis<span class="p">，</span>CCA<a href="part329.htm#bookmark592" class="a">），通过加强两个图视角中表示的相关性，并去相关不同视角中的特征表征</a><a href="part329.htm#bookmark592" class="s33">[84</a><span class="s20">]</span>   <span class="p">。</span></p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">在自监督学习的理论研究中表明：</p><p class="s10" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><span class="p">（</span>1<a href="part329.htm#bookmark593" class="a">）在特定条件下节点级别和特征级别的对比方法是相互对偶的。具体来说，性能差异并非直接由于选择维度，而是由编码器、特征维度和超参数等因素的调整所决定</a><span class="s20">[85]</span> <span class="p">。</span></p><p class="s10" style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><span class="p">（</span>2<a href="part329.htm#bookmark594" class="a">）对比损失和谱图方法之间的联系。利用谱图理论来描述在集群假设下自监督性能的保证</a><span class="s20">[86]</span> <span class="p">。</span></p><p class="s10" style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;"><span class="p">（</span>3<a href="part329.htm#bookmark595" class="a">）对比式和非对比式的自监督方法与全局和局部谱嵌入方法之间的对应关系</a><span class="s20">[89]</span> <span class="p">。通过深入理解自监督学习的理论基础，可以更</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">好地指导和改进相关的自监督学习算法和模型。</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: left;">尽管图自监督学习在不同数据类型和任务中取得了巨大成功，但仍存在一些问题亟待解决。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">1</span>）缺乏坚实的理论基础。目前的研究多是基于经验而非理论的，这导致研究者在提升和设计模型方面缺乏必要的理论基础支持。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">2</span>）未充分利用图数据的独特性。大多数模型设计仍以图像数据处理为基础，而图数据本身具有独特的属性和特征，在自监督学习中没有得到充分的利用和开发。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">3</span>）增广方法存在局限性。虽然增加数据多样性可以提升模型的泛化能力，但当前的图数据增广方法仅限于对拓扑结构和属性进行扰动预处理。因此值得深入研究如何自动选择增强方式或联合多任务生成增强样本。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: left;">（<span class="s10">4</span>）多前置任务的探索不足。目前只有少数方法探讨了多个前 置任务的组合，而整合多样的前置任务可以从多个角度提供监督信号，有助于更好地挖掘图数据的信息。</p><p class="s10" style="padding-left: 7pt;text-indent: 0pt;line-height: 18pt;text-align: left;">6.3.3.4 <span class="s37">图深度生成</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">图深度生成模型可以追溯到两个关键方面的发展。随着图数据在 各个领域中的广泛应用（如社交网络、化学和生物信息学等），人们 对于生成具有图结构的数据的需求越来越迫切。传统的生成模型（如 生成对抗网络和变分自编码器）主要针对向量或序列数据，无法直接 处理和生成图形数据，因此需要新的模型来满足日益增长的需求。图 表示学习的兴起为图深度生成模型的发展提供了基石。图表示学习旨 在学习节点或图的低维表示，以捕捉节点之间的关系和图的结构特征。然而，图表示学习通常关注的是节点级别的特征学习，缺乏对整个图 的生成能力。为了解决这一问题，研究人员开始探索如何在生成模型 的框架下对图结构数据进行建模和生成。</p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">因此，图深度生成模型应运而生，它将深度学习和图表示学习的</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: justify;">思想相结合，致力于学习和模拟图结构数据的生成过程。图深度生成模型可以从潜在空间中学习图的分布，并生成新的图样本。这为模拟和生成复杂的图结构数据提供了一种新的方法，进一步推动了图数据分析和应用领域的发展。</p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">1.<span class="p">图变分自编码器</span></p><p class="s10" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><span class="p">图变分自编码器的基础架构是由编码器和解码器组成的。编码器将输入的图结构数据映射至低维潜在空间，并学习一个潜在变量的后验分布用于表示输入的图结构数据的特征。解码器则将从后验分布中采样的样本映射至原始的图结构数据空间，使得重构的图结构数据和输入的图结构数据尽可能相似。图变分自编码器依赖于变分推断，即假设潜在变量的先验分布和后验分布来解决潜在变量推断的问题，通常选择高斯分布作为先验分布和后验分布。图变分自编码器通过训练来最小化重构误差和 </span>KL <span class="p">散度（</span>Kullback-Leibler Divergence<span class="p">），使得模型能够学习输入的图结构数据的潜在空间并从该空间中生成高质量的样本，其中重构误差衡量重构数据和输入数据之间的差异，</span>KL <a href="part329.htm#bookmark596" class="a">散度衡量潜在变量的先验分布和后验分布之间的差异</a><a href="part329.htm#bookmark596" class="s33">[90</a><span class="s20">]</span><a href="part329.htm#bookmark597" class="s5">   </a><a href="part329.htm#bookmark597" class="s33">-[91</a><span class="s20">]</span>   <span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 24pt;text-indent: 0pt;text-align: left;"><span><img width="502" height="98" alt="image" src="Image_010.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 136pt;text-indent: 0pt;text-align: left;">图 <span class="s25">6-5 </span>图变分自编码器</p><p class="s10" style="padding-top: 4pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">2.<span class="p">图生成对抗网络</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: left;">图生成对抗网络由两个组件组成：生成器和判别器。生成器用于 接收随机噪音或潜在变量作为输入，并试图生成期望的图结构数据。判别器接收生成器生成的图结构数据和真实的图结构数据，并尽力区 分它们。图生成对抗网络通过生成器和判别器的对抗训练来优化模型，即最小化重构损失和最大化对抗损失，其中重构损失衡量生成器生成</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: left;"><a href="part329.htm#bookmark596" class="a">的图结构数据和真实的图结构数据之间的差异，对抗损失衡量判别器区分生成的图结构数据和真实的图结构数据的能力。这使得生成器能够生成更逼真的图结构数据来欺骗判别器，而判别器则能够更好地区分生成的图结构数据和真实的图结构数据。在整个对抗训练过程中，生成器和判别器通过反复的迭代更新来提高各自的性能</a>[90]<span class="s10"> </span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 28pt;text-indent: 0pt;text-align: left;"><span><img width="491" height="200" alt="image" src="Image_011.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 133pt;text-indent: 0pt;text-align: left;">图 <span class="s25">6-6 </span>图生成对抗网络</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">3.<span class="p">图自回归模型</span></p><p class="s20" style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><a href="part329.htm#bookmark597" class="a">图自回归模型通过逐个节点的生成来模拟整个图的生成过程。模型首先选择一个节点遍历顺序，然后按照该顺序逐步生成节点。每个节点的生成依赖于已生成的节点，这通过输入原始的图结构数据进行条件概率分布建模。模型使用循环神经网络或图卷积神经网络等模型来学习节点生成的条件概率。在生成过程中，按照节点遍历顺序逐个生成节点，使用已生成的节点作为输入，并根据条件概率分布生成当前节点的值。在训练过程中，模型通过最大似然估计进行优化，使其能够更好地拟合训练数据。模型通过学习节点生成的条件概率分布以及节点之间的依赖关系，能够捕捉到图的结构和特征，这使得模型能够生成具有类似于训练数据的新的图结构数据</a>[91]<span class="s10"> </span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 22pt;text-indent: 0pt;text-align: left;"><span><img width="508" height="235" alt="image" src="Image_012.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 139pt;text-indent: 0pt;line-height: 22pt;text-align: left;">图 <span class="s25">6-7 </span>图自回归模型</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">4.<span class="p">图归一化流模型</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">图归一化流模型的一般模式为应用一系列可逆的映射函数将输入的图结构数据映射至低维潜在空间的分布中，从该分布中采样的样本通过映射函数的逆函数重新映射至原始的图结构数据空间，从而生成新的图结构数据。图归一化流模型通过最小化生成的图结构数据与真实的图结构数据直接的差异来对模型进行优化，模型以此来学习到将简单的先验分布转换为与真实图分布相匹配的复杂分布的能力</p><p class="s22" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">[92] <span class="s21">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 23pt;text-indent: 0pt;text-align: left;"><span><img width="504" height="99" alt="image" src="Image_013.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 133pt;text-indent: 0pt;text-align: left;">图 <span class="s25">6-8 </span>图归一化流模型</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;">5.<span class="p">图扩散模型</span></p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">受非平衡热力学理论的启发，图扩散生成模型可以被建模为马尔可夫链，包括两个主要阶段，即正向扩散和反向扩散。正向扩散通过</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 139%;text-align: left;"><a href="part329.htm#bookmark599" class="a">向原始输入图结构数据添加噪声（通常是高斯噪声）来产生扩散样本，这一过程旨在引入一定的不确定性和随机性。反向扩散通过训练一个 可学习的反向过程，从扩散样本中恢复出原始输入数据，这一过程可 以是可逆的映射，旨在还原噪声扰动并尽可能接近原始输入。通过最 小化生成数据与原始数据之间的差异对模型进行训练和优化，不断迭 代正向扩散和反向扩散的过程，模型可以学习到图数据的生成和恢复 的规律，逐渐提升生成图结构数据和恢复原始图结构数据的能力</a>[93]<span class="s10"> </span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span><img width="507" height="150" alt="image" src="Image_014.jpg"/></span></p><p class="s24" style="padding-top: 10pt;padding-left: 145pt;text-indent: 0pt;text-align: left;">图 <span class="s25">6-9 </span>图扩散模型</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">图深度生成模型在多个领域中具有广泛的应用。在社交网络分析中，它可以生成逼真的社交网络结构，帮助研究社交网络的性质和演化模式，这有助于研究信息扩散、舆论传播以及应急响应等重大社会事件。对于化学和生物医学领域，图深度生成模型可以生成新的化合物结构，加速药物发现过程，也能够对蛋白质结构进行预测，给予化学和医学领域关键性的技术支持。推荐系统也是图深度生成模型应用的主要场景之一，通过生成用户之间的社交关系图，可以帮助推荐系统更好地理解用户之间的社交连接，生成个性化的推荐结果。在无人驾驶和智能交通领域，模型帮助城市构建智慧交通网络，预测交通网络变化，优化交通规划和管理策略。</p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">图深度生成模型仍然面临一些挑战：</p><p style="padding-top: 7pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">（<span class="s10">1</span>）建模复杂依赖关系：真实图结构数据中的节点拥有多样且</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">复杂的依赖关系，如何准确建模这些关系仍然是一大难题；</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: left;">（<span class="s10">2</span>）大规模的输出空间：对于大规模的图结构数据来说，生成与其相似的新图需要解决检索与其对应的大规模的输出空间的问题；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">3</span>）连续潜变量空间和真实离散数据的矛盾：真实数据是离散的，将其映射为连续潜变量会造成数据失真；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">4</span>）有效的评价指标：对生成的新图如何评价是保障图生成质量的关键环节；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: left;">（<span class="s10">5</span>）复杂多样的有效性需求：属性可控的图结构数据生成是目前的一大难题；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">6</span>）可解释性差的黑盒模型：基于深度学习伴随的可解释性问题。</p><p style="padding-left: 34pt;text-indent: 0pt;text-align: left;">图深度生成模型有着广阔的发展前景：</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 27pt;line-height: 140%;text-align: justify;">（<span class="s10">1</span>）可扩展性：现有图深度生成模型通常有超线性时间复杂度，而真实世界的网络是庞大的，能够扩展到数百万甚至数十亿节点的超大型网络是很重要的；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">2</span>）可解释性：提供可解释的模型对于分子生成、蛋白质结构预测等等现实应用来说是意义深远的，可以极大程度的提高生成图的有效性和准确性；</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: left;">（<span class="s10">3</span>）超越训练数据：数据驱动导致生成图受到训练数据的限制，而生成图的高度新奇性是期望。</p><p style="padding-left: 7pt;text-indent: 27pt;line-height: 139%;text-align: justify;">（<span class="s10">4</span>）动态图：目前仍缺乏对动态图的图生成研究，现有的图深度生成模型通常关注在静态图上，而真实时间的许多图是动态的，并且它们的节点属性和拓扑结构会随时间变化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part114.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part116.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
