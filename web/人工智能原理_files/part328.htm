<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-cn" lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>2 难解问题的智能算法：第 4 章参考文献</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part327.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part329.htm">下一个 &gt;</a></p><p class="s8" style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><a name="bookmark458">2 </a><span class="s9">难解问题的智能算法：第 </span>4 <span class="s9">章参考文献</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -26pt;line-height: 156%;text-align: justify;"><a name="bookmark459">[1] </a><span class="s10">Hutson M. DeepMind AI creates algorithms that sort data faster than those built by people. Nature, 2023, 618(7965): 443-444.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark460">[2] </a><span class="s10">Kool W, van Hoof H, Welling M. Attention, Learn to solve routing problems!. Proceedings of International Conference on Learning Representations. USA (New Orleans, LA): ICLR, 2019.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark461">[3] </a><span class="s10">Chen X, Tian Y. Learning to perform local rewriting for combinatorial optimization. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Garnett eds. Proceedings of the Advances in Neural Information Processing Systems. Canada (Vancouver, BC): NeurIPS, 2019. 6278–6289.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark462">[4] </a><span class="s10">Lu H, Zhang X, Yang S. A learning-based iterative method for solving vehicle routing problems. Proceedings of International Conference on Learning Representations. Ethiopia (Addis Ababa): ICLR, 2020.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark463">[5] </a><span class="s10">Fu Z H, Qiu K B, Zha H. Generalize a small pre-trained model to arbitrarily large TSP instances. Proceedings of the AAAI Conference on Artificial Intelligence. Virtual: AAAI, 2021. 7474-7482.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark464">[6] </a><span class="s10">Jin Y, Ding Y, Pan X, He K, Zhao L, Qin T, Song L, Bian J. Pointerformer: deep reinforced multi-pointer transformer for the traveling salesman problem. Proceedings of the AAAI Conference on Artificial Intelligence. USA (Washington, DC): AAAI, 2023.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark465">[7] </a><span class="s10">Hottung A, Tierney K. Neural large neighborhood search for the capacitated vehicle routing problem. In Giuseppe De Giacomo, Alejandro Catala, Bistra Dilkina, Michela Milano, Senen Barro, Alberto Bugarin, and Jerome Lang eds. Proceedings of the European</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="558" height="1" alt="image" src="Image_126.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: justify;">Conference on Artificial Intelligence. Spain (Santiago de Compostela): ECAI, 2020. 443-450.</p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark466">[8] </a><span class="s10">Delarue A, Anderson R, Tjandraatmadja C. Reinforcement learning with combinatorial actions: an application to vehicle routing. In Hugo Larochelle, Marc&#39;Aurelio Ranzato, Raia Hadsell, Maria- Florina Balcan, and Hsuan-Tien Lin eds. Proceedings of the Advances in Neural Information Processing Systems. Virtual: NeurIPS, 2020.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -26pt;line-height: 155%;text-align: justify;"><a name="bookmark467">[9] </a><span class="s10">Hottung A, Bhandari B, Tierney K. Learning a latent search space for routing problems using variational autoencoders. Proceedings of International Conference on Learning Representations. Austria: ICLR, 2021.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark468">[10] </a><span class="s10">Li S, Yan Z, Wu C. Learning to delegate for large-scale vehicle routing. In Marc&#39;Aurelio Ranzato, Alina Beygelzimer,Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan eds. Proceedings of the Advances in Neural Information Processing Systems. Virtual: NeurIPS, 2021. 26198-26211.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark469">[11] </a><span class="s10">Choo J, Kwon Y D, Kim J, Jae J, Hottung A, Tierney K, Gwon Y. Simulation-guided beam search for neural combinatorial optimization. In Jinho Choo, Yeong-Dae Kwon, Jihoon Kim, Jeongwoo Jae, Andre Hottung, Kevin Tierney, and Youngjune Gwon eds. Proceedings of the Advances in Neural Information Processing Systems. Canada (Vancouver, BC): NeurIPS, 2022. 8760-8772.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark470">[12] </a><span class="s10">Hou Q, Yang J, Su Y, Wang X, Deng Y. Generalize learned heuristics to solve large-scale vehicle routing problems in real-time. Proceedings of International Conference on Learning Representations. Rwanda (Kigali): ICLR, 2023.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s137" style="padding-top: 4pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark471">[13] </a><span class="s10">Xin L, Song W, Cao Z, Zhang J. Multi-decoder attention model with embedding glimpse for solving vehicle routing problems. Proceedings of the AAAI Conference on Artificial Intelligence. USA (Washington, DC): AAAI, 2023. 12042-12049.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark472">[14] </a><span class="s10">Joshi C K, Laurent T, Bresson X. An efficient graph convolutional network technique for the travelling salesman problem. arXiv preprint arXiv:1906.01227, 2019.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark473">[15] </a><span class="s10">Kool W, van Hoof H, Gromicho J, Welling M. Deep policy dynamic programming for vehicle routing problems. In Pierre Schaus ed. Proceedings of Constraint Programming, Artificial Intelligence, and Operations Research, and Operations Research. USA (Los Angeles, CA): CPAIOR, 2022. 190-213.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark474">[16] </a><span class="s10">Barrett T, Clements W, Foerster J, Lvovsky A. Exploratory combinatorial optimization with reinforcement learning. Proceedings of the AAAI Conference on Artificial Intelligence. USA (New York, NY): AAAI, 2020. 3243-3250.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark475">[17] </a><span class="s10">Khalil E, Dai H, Zhang Y, Dilkina B, Song L. Learning combinatorial optimization algorithms over graphs. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett eds. Proceedings of the Advances in Neural Information Processing Systems. USA (Long Beach, CA): NeurIPS, 2017. 26198-26211.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark476">[18] </a><span class="s10">Barrett TD, Parsonson CW, Laterre A. Learning to solve combinatorial graph partitioning problems via efficient exploration. Proceedings of International Conference on Learning Representations. ICLR, 2022.</span></p><p class="s137" style="padding-left: 12pt;text-indent: 0pt;text-align: justify;"><a name="bookmark477">[19] </a><span class="s10">Ireland D, Montana G. Lense: Learning to navigate subgraph</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: justify;">embeddings for large-scale combinatorial optimisation. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato eds. Proceedings of International Conference on Machine Learning, USA (Baltimore, Maryland): ICML, 2022. 9622- 9638.</p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark478">[20] </a><span class="s10">Yao F, Cai R, Wang H. Reversible action design for combinatorial optimization with reinforcement learning. Proceedings of the AAAI Conference on Artificial Intelligence. Canada (Vancouver): AAAI, 2020.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark479">[21] </a><span class="s10">Zhang D, Dai H, Malkin N, et al. Let the flows tell: solving graph combinatorial optimization problems with GFlowNets. arXiv preprint. arXiv:2305.17010, 2023.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark480">[22] </a><span class="s10">Li Z, Chen Q, Koltun V. Combinatorial optimization with graph convolutional networks and guided tree search. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolo Cesa-Bianchi and Roman Garnett eds. Proceedings of the Advances in Neural Information Processing Systems. Canada (Montreal): NeurIPS, 2018. 537-546.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark481">[23] </a><span class="s10">Karalias N, Loukas A. Erdos goes neural: an unsupervised learning framework for combinatorial optimization on graphs. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin eds. Proceedings of the Advances in Neural Information Processing Systems. NeurIPS, 2020. 6659-6672.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark482">[24] </a><span class="s10">Wang L, Hu X, Wang Y, et al. Dynamic job-shop scheduling in smart manufacturing using deep reinforcement learning. Computer Networks, 2021, 190: 107969.</span></p><p class="s137" style="padding-left: 12pt;text-indent: 0pt;text-align: justify;"><a name="bookmark483">[25] </a><span class="s10">Zhang C, Song W, Cao Z, et al. Learning to dispatch for job shop</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: justify;">scheduling via deep reinforcement learning. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin eds. Proceedings of the Advances in Neural Information Processing Systems. NeurIPS, 2020. 1621-1632.</p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark484">[26] </a><span class="s10">Park J, Chun J, Kim SH, Kim Y, Park J. Learning to schedule job- shop problems: representation and policy learning using graph neural network and reinforcement learning. International Journal of Production Research. 2021, 59(11):3360-3377.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark485">[27] </a><span class="s10">Jeon W, Gagrani M, Bartan B, et al. Neural DAG scheduling via one- shot priority sampling. Proceedings of the International Conference on Learning Representations. Rwanda (Kigali): ICLR, 2023.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark486">[28] </a><span class="s10">Park J, Bakhtiyar S, Park J. Schedulenet: learn to solve multi-agent scheduling problems with reinforcement learning. arXiv preprint. arXiv:2106.03051, 2021.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark487">[29] </a><span class="s10">Malherbe C, Grosnit A, Tutunov R, et al. Optimistic tree searches for combinatorial black-box optimization. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho eds. Proceedings of the Advances in Neural Information Processing Systems. USA (Louisiana): NeurIPS, 2022. 33080-33092.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[30] <span class="s10">Amizadeh S, Matusevych S, Weimer M. Learning to solve circuit- sat: an unsupervised differentiable approach. Proceedings of the International Conference on Learning Representations. USA (Louisiana): ICLR, 2018.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[31] <span class="s10">Jaszczur S, Łuszczyk M, Michalewski H. Neural heuristics for SAT solving. arXiv preprint. arXiv:2005.13406, 2020.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 156%;text-align: justify;">[32] <span class="s10">Ozolins E, Freivalds K, Draguns A, et al. Goal-aware neural SAT solver. Proceedings of the International Joint Conference on Neural</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;text-align: justify;">Networks. Italy (Padua): IEEE, 2022. 1-8.</p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 156%;text-align: justify;">[33] <span class="s10">Li M, Shi Z, Lai Q, et al. DeepSAT: an EDA-driven learning framework for SAT. arXiv preprint. arXiv:2205.13745, 2022.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[34] <span class="s10">Karalias N, Robinson J, Loukas A, et al. Neural set function extensions: learning with discrete functions in high dimensions. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho eds. Proceedings of the Advances in Neural Information Processing Systems. USA (Louisiana): NeurIPS, 2022. 15338- 15352.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[35] <span class="s10">Shi Z, Li M, Khan S, et al. Satformer: transformers for SAT solving. arXiv preprint. arXiv:2209.00953, 2022.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark488">[36] </a><span class="s10">Duan H, Nejati S, Trimponias G, et al. Online bayesian moment matching based SAT solver heuristics. In Hal Daumé III and Aarti Singh eds. Proceedings of the International Conference on Machine Learning. PMLR, 2020. 2710-2719.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark489">[37] </a><span class="s10">Wang R, Hua Z, Liu G, et al. A bi-level framework for learning to solve combinatorial optimization on graphs. In Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan eds. Proceedings of the Advances in Neural Information Processing Systems. NeurIPS, 2021. 21453- 21466.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[38] <span class="s10">Lu H, Li Z, Wang R, et al. ROCO: a general framework for evaluating robustness of combinatorial optimization solvers on graphs. Proceedings of the International Conference on Learning Representations. Rwanda (Kigali): ICLR, 2023.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 156%;text-align: justify;">[39] <span class="s10">He Y, Wu G, Chen Y, et al. A two-stage framework and reinforcement learning-based optimization algorithms for complex</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;text-align: justify;">scheduling problems. arXiv preprint. arXiv:2103.05847, 2021.</p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[40] <span class="s10">Mao H, Alizadeh M, Menache I, et al. Resource management with deep reinforcement learning. In Bryan Ford, Alex C. Snoeren, and Ellen W. Zegura eds. Proceedings of the ACM Workshop on Hot Topics in Networks. USA (GA): HotNets, 2016. 50-56.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[41] <span class="s10">Shao Z, Yang J, Shen C, et al. Learning for robust combinatorial optimization: Algorithm and application. Proceedings of IEEE Conference on Computer Communications. London (United Kingdom): INFOCOM, 2022. 930-939.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark490">[42] </a><span class="s10">Fu ZH, Qiu KB, Zha H. Generalize a small pre-trained model to arbitrarily large TSP instances. Proceedings of the 35th AAAI Conference on Artificial Intelligence. Virtual Event: AAAI, 2021. 7474-7482.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[43] <span class="s10">Verma R, Singhal A, Khadilkar H, et al. A generalized reinforcement learning algorithm for online 3d bin-packing. arXiv preprint arXiv:2007.00463, 2020.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[44] <span class="s10">Pejic I, van den Berg D. Monte Carlo tree search on perfect rectangle packing problem instance. In: Carlos Artemio Coello Coello ed. Proceedings of the Genetic and Evolutionary Computation Conference. Mexico: GECCO, 2020. 1697-1703.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark491">[45] </a><span class="s10">Zhu Q, Li X, Zhang Z, et al. Learning to Pack: A data-driven tree search algorithm for large-scale 3d bin packing problem. In: Gianluca Demartini, Guido Zuccon, J. Shane Culpepper, Zi Huang, and Hanghang Tong eds. Proceedings of the International Conference on Information and Knowledge Management. Australia (Queensland): CIKM, 2021. 4393-4402.</span></p><p class="s137" style="padding-left: 12pt;text-indent: 0pt;text-align: justify;"><a name="bookmark492">[46] </a><span class="s10">Bai Y, Ding H, Bian S, et al. Simgnn: A neural network approach to</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: justify;">fast graph similarity computation. In: J. Shane Culpepper, Alistair Moffat, Paul N. Bennett, and Kristina Lerman eds. Proceedings of the ACM International Conference on Web Search and Data Mining. Australia (Melbourne): WSDM, 2019. 384-392.</p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[47] <span class="s10">Li Y, Gu C, Dullien T, et al. Graph matching networks for learning the similarity of graph structured object. In: Kamalika Chaudhuri and Ruslan Salakhutdinov eds. Proceedings of the International Conference on Machine Learning. USA (California): ICML, 2019. 3835-3845.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[48] <span class="s10">Wang R, Zhang T, Yu T, et al. Combinatorial learning of graph edit distance via dynamic embedding. Proceedings of IEEE Conference on Computer Vision and Pattern Recognition. Virtual: CVPR, 2021. 5241-5250.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[49] <span class="s10">Bai Y, Ding H, Gu K, et al. Learning-based efficient graph similarity computation via multi-scale convolutional set matching. Proceedings of the AAAI Conference on Artificial Intelligence. USA (New York): AAAI, 2020. 3219-3226.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark493">[50] </a><span class="s10">Dai X, Yan X, Zhou K, et al. Convolutional embedding for edit distance. In: Jimmy X. Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, JiRong Wen, and Yiqun Liu eds. Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval. Virtual: SIGIR, 2020. 599- 608.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark494">[51] </a><span class="s10">Wang R, Shen L, Chen Y, et al. Towards one-shot neural combinatorial solvers: theoretical and empirical notes on the cardinality-constrained case. Proceedings of the Eleventh International Conference on Learning Representations. Rwanda</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;text-align: justify;">(Kigali): ICLR, 2023.</p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[52] <span class="s10">Meirom E, Maron H, Mannor S, et al. Controlling graph dynamics with reinforcement learning and graph neural networks. In: Marina Meila and Tong Zhang eds. Proceedings of the International Conference on Machine Learning. Virtual Event: ICML, 2021. 7565-7577.</span></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[53] <span class="s10">Grover A, Wang E, Zweig A, et al. Stochastic optimization of sorting networks via continuous relaxations. Proceedings of the International Conference on Learning Representations. USA (New Orleans): ICLR, 2019.</span></p><p class="s137" style="padding-left: 12pt;text-indent: 0pt;text-align: justify;">[54] <span class="s10">Xie Y, Dai H, Chen M, et al. Differentiable top-k with optimal</span></p><p class="s10" style="padding-top: 2pt;padding-left: 42pt;text-indent: 0pt;line-height: 25pt;text-align: justify;">transport. In <span class="s138">； </span>Hugo Larochelle, Marc&#39;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin eds. Proceedings of the Advances in Neural Information Processing</p><p class="s10" style="padding-top: 6pt;padding-left: 42pt;text-indent: 0pt;text-align: justify;">Systems. Virtual: NeurIPS, 2020. 20520-20531.</p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark495">[55] </a><span class="s10">Swezey R, Grover A, Charron B, et al. Pirank: Scalable learning to rank via differentiable sorting. In: Marc&#39;Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan eds. Proceedings of the Advances in Neural Information Processing Systems. Virtual: NeurIPS, 2021. 21644-21654.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark496">[56] </a><span class="s10">Silver D, Hubert T, Schrittwieser J, et al. Mastering chess and shogi by self-play with a general reinforcement learning algorithm. arXiv preprint arXiv:1712.01815, 2017.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark497">[57] </a><span class="s10">Silver D, Schrittwieser J, Simonyan K, et al. Mastering the game of Go without human knowledge. Nature, 2017. 354-359.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 12pt;text-indent: 0pt;text-align: justify;">[58] <span class="s10">Huang J, Patwary M, Diamos G. Coloring Big Graphs with</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;text-align: left;">AlphaGoZero. arXiv preprint arXiv:1902.10162, 2019.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[59] <span class="s10">Laterre A, Fu Y, Jabri M K, et al. Ranked reward: enabling self-play reinforcement learning for combinatorial optimization. arXiv preprint arXiv: 1807.01672, 2018.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;">[60] <span class="s10">Li Z, Chen Q, Koltun V. Combinatorial optimization with graph convolutional networks and guided tree search. In: Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolo Cesa-Bianchi, and Roman Garnett eds. Proceedings of the Advances in Neural Information Processing Systems. Canada (Montreal): NeurIPS, 2018. 537-546.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 156%;text-align: justify;">[61] <span class="s10">Qi W. Alpha-T: learning to traverse over graphs with an AlphaZero- inspired Self-Play framework. Research Square, 2021.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark498">[62] </a><span class="s10">Watkins C J C H, Dayan P. Q-learning. Machine learning, 1992, 8: 279-292.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark499">[63] </a><span class="s10">Osband I, Blundell C, Pritzel A, et al. Deep exploration via bootstrapped DQN. In: Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon and Roman Garnett eds. Proceeding of the Advances in Neural Information Processing Systems. Spain (Barcelona): NeurIPS, 2016. 4026-4034.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark500">[64] </a><span class="s10">Anschel O, Baram N, Shimkin N. Averaged-dqn: variance reduction and stabilization for deep reinforcement learning. In: Doina Precup and Yee Whye Teh eds. Proceeding of the International Conference on Machine Learning. Australia (Sydney): PMLR, 2017. 176-185.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark501">[65] </a><span class="s10">Khalil E, Dai H, Zhang Y, et al. Learning combinatorial optimization algorithms over graphs. In: Isabelle Guyon, Ulrike von Luxburg,</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="558" height="1" alt="image" src="Image_127.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: justify;">Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan and Roman Garnett eds. Proceeding of the Advances in Neural Information Processing Systems. USA (Long Beach, CA): NeurIPS, 2017. 6348-6358.</p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark502">[66] </a><span class="s10">Cappart Q, Goutierre E, Bergman D, et al. Improving optimization bounds using machine learning: decision diagrams meet deep reinforcement learning. Proceedings of the AAAI Conference on Artificial Intelligence. USA (Honolulu, Hawaii): AAAI, 2019. 1443- 1451.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark503">[67] </a><span class="s10">Bai Y, Xu D, Wang A, et al. Fast detection of maximum common subgraph via deep Q-learning. arXiv preprint. arXiv:2002.03129, 2020.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark504">[68] </a><span class="s10">Song J, Lanka R, Yue Y, et al. Co-training for policy learning. In: Amir Globerson and Ricardo Silva eds. Proceedings of the Conference on Uncertainty in Artificial Intelligence. Israel (Tel Aviv): AUAI, 2019. 1191-1201.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark505">[69] </a><span class="s10">Barrett T, Clements W, Foerster J, et al. Exploratory combinatorial optimization with reinforcement learning. Proceedings of the AAAI Conference on Artificial Intelligence. USA (New York, NY): AAAI, 2020. 3243-3250.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark506">[70] </a><span class="s10">Liao H, Zhang W, Dong X, et al. A deep reinforcement learning approach for global routing. Journal of Mechanical Design, 2020, 142(6): 061701.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark507">[71] </a><span class="s10">Scavuzzo L, Chen F, Chételat D, et al. Learning to branch with tree mdps. In: Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: justify;">Kyunghyun Cho eds. Proceedings of the Advances in Neural Information Processing Systems. USA (Louisiana): NeurIPS, 2022. 18514-18526.</p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark508">[72] </a><span class="s10">Qu Q, Li X, Zhou Y, et al. An improved reinforcement learning algorithm for learning to branch. arXiv preprint. arXiv:2201.06213, 2022.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark509">[73] </a><span class="s10">Wang J, Zhao L, Liu J, et al. Smart resource allocation for mobile edge computing: A deep reinforcement learning approach. IEEE Transactions on Emerging Topics in Computing, 2019, 9(3): 1529- 1541.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark510">[74] </a><span class="s10">He Y, Wu G, Chen Y, et al. A two-stage framework and reinforcement learning-based optimization algorithms for complex scheduling problems. arXiv preprint. arXiv:2103.05847, 2021.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark511">[75] </a><span class="s10">Jacobs T, Alesiani F, Ermis G, et al. Reinforcement learning for route optimization with robustness guarantees. In: Zhihua Z ed. Proceedings of the International Joint Conference on Artificial Intelligence. Canada (Montreal): IJCAI, 2021. 2592-2598.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark512">[76] </a><span class="s10">Tang Y, Agrawal S, Faenza Y. Reinforcement learning for integer programming: learning to cut. arXiv preprint arXiv:1906.04859, 2019.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark513">[77] </a><span class="s10">Yolcu E, Póczos B. Learning local search heuristics for boolean satisfiability. Proceedings of the International Conference on Machine Learning. Virtual Event: PMLR, 2020. 9367-9376.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark514">[78] </a><span class="s10">Ma Q, Ge S, He D, et al. Combinatorial optimization by graph pointer networks and hierarchical reinforcement learning. arXiv</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;text-align: left;">preprint. arXiv:1911.04936, 2019.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s137" style="padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark515">[79] </a><span class="s10">Nazari M, Oroojlooy A, Snyder L, et al. Reinforcement learning for solving the vehicle routing problem. In: Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolo Cesa-Bianchi, and Roman Garnett eds. Proceeding of the Advances in Neural Information Processing Systems. Canada (Montreal): NeurIPS, 2018. 9839-9849.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark516">[80] </a><span class="s10">Deudon M, Cournut P, Lacoste A, et al. Learning heuristics for the TSP by policy gradient. In: Michel Deudon, Pierre Cournut, Alexandre Lacoste, Yossiri Adulyasak, and Louis-Martin Rousseau eds. Integration of Constraint Programming, Artificial Intelligence, and Operations Research. Delft, The Netherlands: Springer, 2018. 170-181.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark517">[81] </a><span class="s10">Kool W, van Hoof H, Welling M. Attention, learn to solve routing problems. Proceedings of the International Conference on Learning Representations. USA (New Orleans, LA): ICLR, 2018.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark518">[82] </a><span class="s10">Bello I, Pham H, Le Q V, et al. Neural combinatorial optimization with reinforcement learning. Proceedings of the International Conference on Learning Representations. France (Toulon): ICLR, 2017.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark519">[83] </a><span class="s10">Hu H, Zhang X, Yan X, et al. Solving a new 3d bin packing problem with deep reinforcement learning method. arXiv preprint arXiv:1708.05930, 2017.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark520">[84] </a><span class="s10">Lu H, Zhang X, Yang S. A learning-based iterative method for solving vehicle routing problems. Proceedings of the International</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: left;">Conference on Learning Representations. Ethiopia (Addis Ababa): ICLR, 2020.</p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark521">[85] </a><span class="s10">Sun H, Chen W, Li H, et al. Improving learning to branch via reinforcement learning. Learning Meets Combinatorial Algorithms at NeurIPS 2020.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark522">[86] </a><span class="s10">Emami P, Ranka S. Learning permutations with sinkhorn policy gradient. arXiv preprint arXiv:1805.07010, 2018.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark523">[87] </a><span class="s10">Chen X, Tian Y. Learning to perform local rewriting for combinatorial optimization. In: Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Garnett eds. Proceedings of the Advances in Neural Information Processing Systems. Canada (Vancouver, BC): NeurIPS, 2019. 6278–6289.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark524">[88] </a><span class="s10">Malazgirt G A, Unsal O S, Kestelman A C. Tauriel: Targeting traveling salesman problem with a deep reinforcement learning inspired architecture. arXiv preprint arXiv:1905.05567, 2019.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark525">[89] </a><span class="s10">Cappart Q, Moisan T, Rousseau L M, et al. Combining reinforcement learning and constraint programming for combinatorial optimization. Proceedings of the AAAI Conference on Artificial Intelligence. Virtual: AAAI, 2021. 3677-3687.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark526">[90] </a><span class="s10">Gao L, Chen M, Chen Q, et al. Learn to design the heuristics for vehicle routing problem. arXiv preprint arXiv:2002.08539, 2020.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark527">[91] </a><span class="s10">Silver D, Hubert T, Schrittwieser J, et al. Mastering chess and shogi by self-play with a general reinforcement learning algorithm. arXiv preprint arXiv:1712.01815, 2017.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s137" style="padding-top: 4pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark528">[92] </a><span class="s10">Laterre A, Fu Y, Jabri M K, et al. Ranked reward: Enabling self-play reinforcement learning for combinatorial optimization. arXiv preprint arXiv:1807.01672, 2018.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark529">[93] </a><span class="s10">Silver D, Schrittwieser J, Simonyan K, et al. Mastering the game of Go without human knowledge. Nature, 2017, 550(7676): 354-359.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark530">[94] </a><span class="s10">Abe K, Xu Z, Sato I, et al. Solving np-hard problems on graphs with extended alphago zero. arXiv preprint arXiv:1905.11623, 2019.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark531">[95] </a><span class="s10">Li Z, Chen Q, Koltun V. Combinatorial optimization with graph convolutional networks and guided tree search. In: Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, NicoloCesa-Bianchi, and Roman Garnett eds. Proceedings of the International Conference on Neural Information Processing Systems. Canada (Montreal): NeurIPS, 2018. 537-546.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 156%;text-align: justify;"><a name="bookmark532">[96] </a><span class="s10">Huang J, Patwary M, Diamos G. Coloring big graphs with alphagozero. arXiv preprint arXiv:1902.10162, 2019.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark533">[97] </a><span class="s10">Wang Q. Alpha-T: learning to traverse over graphs with an AlphaZero-inspired Self-Play framework. Research Square, 2021.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark534">[98] </a><span class="s10">Pierrot T, Ligner G, Reed S, et al. Learning compositional neural programs with recursive tree search and planning. In: Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alche- Buc, Emily B. Fox, and Roman Garnett eds. Proceedings of the Advances in Neural Information Processing Systems. Canada (Vancouver, BC): NeurIPS 2019. 14673-14683</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -30pt;line-height: 155%;text-align: justify;"><a name="bookmark535">[99] </a><span class="s10">Xu R, Lieberherr K. Learning self-game-play agents for combinatorial optimization problems. In: Edith Elkind, Manuela</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;line-height: 155%;text-align: justify;">Veloso, Noa Agmon, and Matthew E. Taylor eds. Proceedings of the International Conference on Autonomous Agents and MultiAgent Systems. Canada (Montreal): AAMAS, 2019. 2276-2278.</p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -34pt;line-height: 155%;text-align: justify;">[100] <span class="s10">Zeng X, Peng H, Li A. Effective and stable role-based multi-agent collaboration by structural information principles. arXiv preprint arXiv:2304.00755, 2023.</span></p><p class="s137" style="padding-top: 7pt;padding-left: 42pt;text-indent: -34pt;line-height: 155%;text-align: justify;">[101] <span class="s10">Yang Z, Zhang G, Wu J, et al. Minimum entropy principle guided graph neural networks. In: Tat-Seng Chua, Hady W. Lauw, Luo Si, Evimaria Terzi, and Panayiotis Tsapara eds. Proceedings of the ACM International Conference on Web Search and Data Mining. Singapore: WSDM, 2023. 114-122.</span></p><p class="s137" style="padding-top: 8pt;padding-left: 42pt;text-indent: -34pt;line-height: 155%;text-align: justify;">[102] <span class="s10">Wu J, Li S, Li J, et al. A simple yet effective method for graph classification. In: Luc De Raedt ed. Proceedings of the International Joint Conference on Artificial Intelligence. Austria (Vienna): IJCAI, 2022. 3580-3586.</span></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part327.htm">&lt; 上一个</a><span> | </span><a href="../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86.html">内容</a><span> | </span><a href="part329.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
