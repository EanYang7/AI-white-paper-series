<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>2.5.3 利用云计算资源应对算力需求挑战</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part27.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a><span> | </span><a href="part29.htm">下一个 &gt;</a></p><h4 style="padding-top: 12pt;padding-left: 10pt;text-indent: 0pt;text-align: left;"><a name="bookmark58">2.5.3 </a><span class="s17">利用云计算资源应对算力需求挑战</span><a name="bookmark125">&zwnj;</a></h4><p class="s9" style="padding-top: 7pt;padding-left: 10pt;text-indent: 0pt;text-align: left;"><a name="bookmark59">2.5.3.1 Stable Diffusion WebUI </a><span class="s18">的应用瓶颈</span></p><p style="padding-top: 7pt;padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;">虽然<span class="s9">Stable Diffusion WebUI </span>非常流行，它的图形化操作界面大大降低了普通用户进行<span class="s9">AI </span>生图的门槛，但在实际应用中，用户通常会面临一些限制，影响工作和创新的效率。<span class="s9">Stable Diffusion WebUI </span>是单机版应用，对设备要求高，需要配有图形处理单元 <span class="s9">(GPU) </span>才能顺畅地生成图像。用户一般使用带有<span class="s9">GPU </span>显卡的本地计算机或租用云环</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;line-height: 139%;text-align: justify;">境中带有 <span class="s9">GPU </span>设备的虚拟机，在其中安装和运行 <span class="s9">Stable Diffusion WebUI</span>。更为严重的是，单机版的计算资源有限，每次只能执行一个工作负载。一旦当前任务开始，界面就不会再允许提交新任务，直到当前的任务完成。这种单机运行模式会极大地影响用户开展<span class="s9">AI </span>生图工作的效率。</p><p class="s9" style="padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;">Stable Diffusion WebUI <span class="p">在实际应用中面临的限制，是普遍存在的生成式</span>AI <span class="p">高算力要求的一个侧影。由于生成式 </span>AI <span class="p">需要处理庞大的数据集和复杂的模型，其训练和推理的过程需要大量的计算资源。运行较大规模的生成式</span>AI <span class="p">模型，通常需要高性能的硬件设备，如图形处理单元 </span>(GPU) <span class="p">或专用的 </span>AI <span class="p">加速器。这些设备能够并行处理大规模的矩阵运算和神经网络计算，以加快模型的训练和生成速度。此外，生成式</span>AI <span class="p">的训练过程通常需要较长时间，甚至需要多天或数周才能完成。这期间，对于训练过程的自动化监控与调度，以及对结果的自动评估，都是生成式</span>AI <span class="p">在实际中得到更大范围应用所面临的挑战。</span></p><p class="s9" style="padding-left: 10pt;text-indent: 0pt;text-align: left;"><a name="bookmark60">2.5.3.2 </a><span class="s18">向云端寻求弹性算力资源</span></p><p class="s9" style="padding-top: 7pt;padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;"><span class="p">随着生成式</span>AI <span class="p">的发展，面对更大规模的数据集、更复杂的模型和更高质量的生成结果需求，人们将目光投向云计算服务，以获得更强大的计算能力和工程化平台的支持。实际上，目前很多流行的大模型都是在云计算平台上完成的训练。例如，</span>Stable Diffusion <span class="p">模型就是在 </span>Amazon SageMaker <a href="part28.htm#bookmark126" class="s6">服 务 上 完 成 训 练 的 </a><a href="part28.htm#bookmark126" class="s19">38</a> <span class="p">。 借 助 </span>Amazon SageMaker<span class="p">，</span>Stability AI (Stable Diffusion <span class="p">模型的开发公司</span>) <span class="p">在具有数千个</span>GPU <span class="p">或</span>Amazon Trainium <span class="p">芯片的计算集群上构建</span>AI <span class="p">模型，从而将训练时间和成本缩短 </span>58%<span class="p">。</span></p><p style="padding-left: 10pt;text-indent: 27pt;line-height: 140%;text-align: justify;">利用拥有弹性和高可用算力支持的云计算已成为大规模开展生成式<span class="s9">AI </span>实践的重要途径。通过云计算平台，生成式 <span class="s9">AI </span>可以利用弹性</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-left: 28pt;text-indent: 0pt;text-align: left;"><a name="bookmark126">38</a><span class="s21">https://aws.amazon.com/blogs/machine-learning/stability-ai-builds-foundation-models-on-amazon-sagemak</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">er/</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;line-height: 139%;text-align: justify;">的资源分配和并行计算能力，加快训练和推理速度；同时，还可以利用丰富的云服务构建起灵活实用、可快速迭代的工程化系统，为创新和应用提供基础环境。</p><p style="padding-left: 38pt;text-indent: 0pt;text-align: left;">在云端拓展算力的方式主要有两类，以 <span class="s9">Stable Diffusion WebUI</span></p><p style="padding-top: 7pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">的使用为例：</p><p class="s9" style="padding-top: 7pt;padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;">(1) <span class="p">云虚拟主机。用户在云计算平台租用配有 </span>GPU <span class="p">等加速设备的虚拟机，</span>AI <span class="p">生成工作完成后即可释放资源。目前，很多云计算服务商针对生成式 </span>AI <span class="p">业务提供专门的虚拟机类型，在虚拟机上预置好 </span>Stable Diffusion WebUI <span class="p">环境和相应的模型文件，便于用户开机即用。用户在使用体验上与在本地没有区别，仍然会受限于所使用的虚拟机上的</span>GPU <span class="p">资源。当设计任务较多时，仍然会遇到任务队列的瓶颈。由于应用的前端和后端都全部位于同一台虚拟机上，算力依旧依赖于前端所在的这台虚拟机，所以在应用架构上，与在本地自购主机没有本质区别。</span></p><p class="s9" style="padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;">(2) <span class="p">后端云算力。面对大规模生成式 </span>AI <span class="p">任务需求，往往采用更高效灵活的前后端分离方式。</span>Stable Diffusion WebUI <span class="p">作为应用前端，被部署在低配置的云虚拟机或本地主机上；当需要推理或训练时，调用后端独立的高性能虚拟机。这样，针对训练和推理，分别配置为不同场景专门优化过的机型；针对不同的生成工作量，配置不同数量的算力资源，以实现并发加速。在亚马逊云科技的平台上，还可以使用 </span>Spot <span class="p">实例，充分利用闲置的计算资源，获得更高的性价比。</span></p><p class="s9" style="padding-left: 10pt;text-indent: 0pt;text-align: left;"><a name="bookmark61">2.5.3.3 </a><span class="s18">亚马逊云科技的算力与</span>AI <span class="s18">研发资源</span></p><p class="s9" style="padding-top: 7pt;padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;">Stability AI <span class="p">公司所使用的</span>Amazon SageMaker <span class="p">是亚马逊云科技的全托管的一站式机器学习开发平台，面向生成式</span>AI <span class="p">的算法和模型开发人员，帮助用户高效实现生成式</span>AI <span class="p">基础模型的训练、推理、自定义、微调、部署和管理。通过 </span>Amazon SageMaker<span class="p">，用户不仅可以轻松访问包括 </span>Nvidia GPU<span class="p">、</span>Amazon Trainium <span class="p">在内的最新的基础设施</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;line-height: 139%;text-align: justify;">资源，利用 <span class="s9">Studio</span>、<span class="s9">Notebook </span>等一系列调试、分析和追踪模型效果的工具，轻松实践机器学习运维 <span class="s9">MLOps </span>、大规模集群协调和分布式训练，还可以获得专门优化的机器学习框架和库、高性价比的 <span class="s9">Spot </span>实例支持、多种推理方式的部署、大语言模型并行化处理等多种特性，最大限度地节省模型开发和应用成本，提升整体生产效率。</p><p class="s9" style="padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;">SageMaker JumpStart <span class="p">是 </span>Amazon SageMaker <span class="p">提供的一个资源中心，目前内置 </span>300 <span class="p">多种开源模型和 </span>10 <span class="p">多种预设场景解决方案。通过 </span>SageMaker JumpStart<span class="p">，用户能够一键部署或微调包括</span>Stable Diffusion<span class="p">在内的主流生成式</span>AI <span class="p">开源模型，低代码地轻松开发高质量模型，并缩短部署时间。同时，它还支持对大量模型的管理，包括搜索和共享。</span></p><p style="padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: left;">在硬件层面，用户需要高性能、低成本且为机器学习专门构建的基础设施。亚马逊云科技不仅提供基于英伟达最新 <span class="s9">GPU </span>芯片 <span class="s9">(</span>如 <span class="s9">H100</span>、<span class="s9">A100</span>、<span class="s9">A10</span>、<span class="s9">T4 </span>等<span class="s9">) </span>的虚拟机实例，还提供基于自研<span class="s9">AI </span>训练 <span class="s9">(Trainium) </span>与推理 <span class="s9">(Inferentia) </span>芯片、专门针对生成式 <span class="s9">AI </span>应用优化的高性价比虚拟机实例，帮助用户大幅节省生成式<span class="s9">AI </span>训练和推理的成本。与其他类似的 <span class="s9">Amazon EC2 </span>实例相比，采用 <span class="s9">Trainium </span>训练芯片的实例<span class="s9">Trn1 </span>可以节省高达 <span class="s9">50%</span>的训练成本，经过优化后可以在与高达 <span class="s9">800Gbps </span>的第二代 <span class="s9">EFA (</span>弹性结构适配器<span class="s9">) </span>网络相连的多个服务器上分发训练任务；采用<span class="s9">Inferentia2 </span>推理芯片的实例<span class="s9">Inf2</span>，吞吐量提高了 <span class="s9">4 </span>倍，延迟降低了 <span class="s9">10 </span>倍，支持包括<span class="s9">Stable Diffusion 2.1 </span>在内的大量生成式<span class="s9">AI </span>的基础模型，在图片生成时间、<span class="s9">QPS (</span>每秒查询推理响应速度<span class="s9">)</span>、服务器推理成本上有较大优势。</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part27.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a><span> | </span><a href="part29.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
