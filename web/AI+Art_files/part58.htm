<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>参考文献</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part57.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a></p><p class="s8" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: center;"><a name="bookmark314">参考文献</a><a name="bookmark315">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 59pt;text-indent: -37pt;line-height: 139%;text-align: left;"><span class="s80">[1]      </span>张晓欢<span class="s9">.</span>数字文化产业发展的趋势，问题与对策建议<span class="s9">.</span>重庆理工大学学报（社会科学），<span class="s9">2021</span>（<span class="s9">02</span>）：<span class="s9">1-7.[</span>期刊<span class="s9">]</span></p><p style="padding-left: 22pt;text-indent: 0pt;text-align: left;"><span class="s80">[2]      </span>张伟，吴晶琦<span class="s9">.</span>数字文化产业新业态及发展趋势<span class="s9">.</span>深圳大学学报</p><p style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">（人文社会科学版）<span class="s9">.2022</span>（<span class="s9">1</span>）：<span class="s9">60-68.[</span>期刊<span class="s9">]</span></p><p style="padding-top: 7pt;padding-left: 59pt;text-indent: -37pt;line-height: 140%;text-align: left;"><span class="s80">[3]      </span>陈美华，黄轩，陈东有<span class="s9">.</span>我国数字出版产业的困境及对策研究<span class="s9">.</span>江西社会科学<span class="s9">.2017,37(12)</span>：<span class="s9">88-94.[</span>期刊<span class="s9">]</span></p><p style="padding-left: 59pt;text-indent: -37pt;line-height: 139%;text-align: left;"><span class="s80">[4]      </span>张显龙<span class="s9">. </span>筹划网络空间战略 促进网络文化发展<span class="s9">. </span>中国信息安全， <span class="s9">2013 (8): 50-52.[</span>期刊<span class="s9">]</span></p><p style="padding-left: 59pt;text-indent: -37pt;line-height: 139%;text-align: left;"><span class="s80">[5]      </span>范周<span class="s9">. </span>数字经济变革中的文化产业创新与发展<span class="s9">. </span>《 深圳大学学报》（人文社科版）， <span class="s9">2020, 37(1): 50-56.[</span>期刊<span class="s9">]</span></p><p style="padding-left: 22pt;text-indent: 0pt;text-align: left;"><span class="s80">[6]      </span>黄永林<span class="s9">. </span>数字经济时代文化消费的特征与升级<span class="s9">. </span>人民论坛，</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">2022, 9: 116-121.[<span class="p">期刊</span>]</p><p style="padding-top: 7pt;padding-left: 59pt;text-indent: -37pt;line-height: 139%;text-align: justify;"><span class="s80">[7] </span>钟义信<span class="s9">. </span>人工智能： 概念· 方法· 机遇<span class="s9">.</span>科学通报， <span class="s9">2017, 62(22): 2473-2479.[</span>期刊<span class="s9">]</span></p><p style="padding-left: 22pt;text-indent: 0pt;text-align: left;"><span class="s80">[8]      </span>陈骞<span class="s9">. </span>国外 “人工智能<span class="s9">+ </span>文化” 发展新看点<span class="s9">. </span>上海信息化，</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">2021 (6): 53-55.[<span class="p">期刊</span>]</p><p style="padding-top: 7pt;padding-left: 59pt;text-indent: -37pt;line-height: 140%;text-align: left;"><span class="s80">[9]      </span>付茜茜<span class="s9">. </span>人工智能时代的社会文化发展： 机遇， 挑战与应对<span class="s9">.</span>新疆社会科学， <span class="s9">2021.[</span>期刊<span class="s9">]</span></p><p style="padding-left: 59pt;text-indent: -40pt;line-height: 139%;text-align: left;"><span class="s80">[10]     </span>陈永伟<span class="s9">.</span>超越<span class="s9">ChatGPT</span>：生成式 <span class="s9">AI </span>的机遇、风险与挑战<span class="s9">.</span>山东大学学报（哲学社会科学版）：<span class="s9">1-18[2023-03-13].[</span>期刊<span class="s9">]</span></p><p style="padding-left: 59pt;text-indent: -40pt;line-height: 147%;text-align: justify;"><span class="s80">[11] </span>马立新， 涂少辉<span class="s9">.AI </span>艺术创作机理研究<span class="s9">. </span>美术研究， <span class="s9">2022,No.204(06):82-86.DOI:10.13318/j.cnki.msyj.2022.06.016.[</span>期刊<span class="s9">]</span></p><p style="padding-left: 18pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><span class="s80">[12]     </span>于翔<span class="s9">. </span>基于 <span class="s9">AlexNet </span>的南通蓝印花布纹样分类<span class="s9">. </span>中国新通</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">信<span class="s9">.2021(06):45-147.[</span>期刊<span class="s9">]</span></p><p style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 139%;text-align: left;"><span class="s80">[13]     </span>邱志杰<span class="s9">.</span>讲好当代艺术的中国故事<span class="s9">.</span>人民论坛，<span class="s9">2023(14):104-106. [</span>期刊<span class="s9">]</span></p><p style="padding-left: 59pt;text-indent: -40pt;line-height: 139%;text-align: left;"><span class="s80">[14]     </span>邱志杰<span class="s9">.</span>科普即美育<span class="s9">.</span>自然科学博物馆研究，<span class="s9">2021,6(05):5-11[</span>期刊<span class="s9">]</span></p><p style="padding-left: 18pt;text-indent: 0pt;text-align: left;"><span class="s80">[15]     </span>邱志杰<span class="s9">.</span>科技艺术的概念<span class="s9">.</span>美术研究，<span class="s9">2020(06):30-32+[</span>期刊<span class="s9">]</span></p><p style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 139%;text-align: left;"><span class="s80">[16]     </span>邱志杰<span class="s9">.</span>科技热潮与策展的责任<span class="s9">[J].</span>美术馆<span class="s9">,2020(02):162-163. [</span>期刊<span class="s9">]</span></p><p style="padding-left: 18pt;text-indent: 0pt;text-align: left;"><span class="s80">[17]     </span>邱 志 杰 <span class="s9">. </span>百 年 荏 苒 ： 实 验 艺 术 在 中 <span class="s9">. </span>美 术 研 究 ，</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">2019(05):22-32+41-43. [<span class="p">期刊</span>]</p><p style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 139%;text-align: left;"><span class="s80">[18]     </span>陈抱阳，吴啸海，江上越，张文超，商亮，卢征远，叶甫纳“中央美术学院青年艺术家国际驻地艺术实践”作品<span class="s9">. </span>美术研究</p><p style="padding-left: 59pt;text-indent: 0pt;text-align: left;">（<span class="s9">06</span>），<span class="s9">94-95.[</span>期刊<span class="s9">]</span></p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 149%;text-align: left;"><span class="s80">[19]     </span>Epstein Z, Levine S, Rand D G, et al. Who gets credit for ai-generated art? Iscience, 2020, 23(9): 101515.[<span class="p">期刊</span>]</p><p class="s9" style="padding-left: 18pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s80">[20]     </span>Kaixuan Liu , Shunmuzi Zhou, Chun Zhu, and Zhao Lü<span class="p">，</span>Virtual</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;line-height: 149%;text-align: left;">simulation of Yue Opera costumes and fashion design based on Yue Opera elements, Fashion and Textiles, (2022) 9:31.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">[21] <span class="s9">Cetinic E, She J. Understanding and creating art with AI: review</span></p><p class="s9" style="padding-top: 9pt;padding-left: 59pt;text-indent: 0pt;line-height: 153%;text-align: justify;">and outlook. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 2022, 18(2): 1-22.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">[22] <span class="s9">Sohl-Dickstein J., et al. Deep unsupervised learning using</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 150%;text-align: justify;">nonequilibrium thermodynamics. International conference on machine learning. PMLR, pages 2256-2265, 2015.[<span class="p">会议录</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">[23] <span class="s9">Ramesh A., et al. Hierarchical text-conditional image generation</span></p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;text-align: justify;">with clip latents. arXiv preprint arXiv:2204.06125, 2022.[<span class="p">期刊</span>]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s9" style="padding-top: 4pt;padding-left: 59pt;text-indent: -40pt;line-height: 154%;text-align: justify;"><span class="s80">[24] </span>Rombach R., et al. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684-10695, 2022.[<span class="p">会议录</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">[25] <span class="s9">Ho J., et al. Denoising diffusion probabilistic models. Advances in</span></p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;line-height: 140%;text-align: justify;">neural information processing systems, 2020, 33: 6840-6851.[<span class="p">期刊</span>]</p><p class="s9" style="padding-left: 59pt;text-indent: -40pt;line-height: 153%;text-align: justify;"><span class="s80">[26] </span>Blei D. M., et al. Variational inference: A review for statisticians. Journal of the American statistical Association, 2017, 112(518): 859-877.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">[27] <span class="s9">Dhariwal P., et al. Diffusion models beat gans on image synthesis.</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 150%;text-align: justify;">Advances in neural information processing systems, 2021, 34: 8780-8794. [<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">[28] <span class="s9">Luo C. Understanding diffusion models: A unified perspective.</span></p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;text-align: justify;">arXiv preprint arXiv:2208.11970, 2022.[<span class="p">期刊</span>]</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 153%;text-align: justify;"><span class="s80">[29] </span>Brown T., et al. Language models are few-shot learners. Advances in neural information processing systems, 2020, 33: 1877-1901.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">[30] <span class="s9">Hu J. E., et al. Lora: Low-rank adaptation of large language</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;text-align: justify;">models. arXiv preprint arXiv:2106.09685, 2021.[<span class="p">期刊</span>]</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 150%;text-align: justify;"><span class="s80">[31] </span>Liu Y., et al. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019. [<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">[32] <span class="s9">He P., et al. Deberta: Decoding-enhanced bert with disentangled</span></p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: 0pt;text-align: justify;">attention. arXiv preprint arXiv:2006.03654, 2020.[<span class="p">期刊</span>]</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 150%;text-align: justify;"><span class="s80">[33] </span>Radford A., et al. Language models are unsupervised multitask learners. OpenAI blog, 2019, 1(8): 9.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">[34] <span class="s9">Li C., et al. Measuring the intrinsic dimension of objective</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s9" style="padding-top: 3pt;padding-left: 59pt;text-indent: 0pt;text-align: justify;">landscapes. arXiv preprint arXiv:1804.08838, 2018.[<span class="p">期刊</span>]</p><p class="s9" style="padding-top: 7pt;padding-left: 59pt;text-indent: -40pt;line-height: 153%;text-align: justify;"><span class="s80">[35] </span>Aghajanyan A., et al. Intrinsic dimensionality explains the effectiveness of language model fine-tuning. arXiv preprint arXiv:2012.13255, 2020.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">[36] <span class="s9">Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). ImageNet</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 153%;text-align: justify;">classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105).[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: left;">[37]     <span class="s9">Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need.</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 150%;text-align: left;">Advances in neural information processing systems, 2017, 30.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: left;">[38]       <span class="s9">Devlin J, Chang M W, Lee K, et al. Bert: Pre-training of deep</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 150%;text-align: left;">bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: left;">[39]       <span class="s9">Dosovitskiy A, Beyer L, Kolesnikov A, et al. An image is worth</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 150%;text-align: left;">16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: left;">[40]     <span class="s9">Karras T, Laine S, Aila T. A style-based generator architecture for</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 153%;text-align: justify;">generative adversarial networks.Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019: 4401-4410.[<span class="p">会议录</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: left;">[41]       <span class="s9">Goodfellow I, Pouget-Abadie J, Mirza M, et al. Generative</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 149%;text-align: left;">adversarial nets. Advances in neural information processing systems, 2014, 27.[<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: left;">[42]     <span class="s9">Song J., et al. Denoising diffusion implicit models. arXiv preprint</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">arXiv:2010.02502, 2020.[<span class="p">期刊</span>]</p><p class="s80" style="padding-top: 8pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">[43]     <span class="s9">Li, J., et al. Blip: Bootstrapping language-image pre-training for</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s9" style="padding-top: 4pt;padding-left: 59pt;text-indent: 0pt;line-height: 145%;text-align: justify;">unified vision-language understanding and generation. International Conference on Machine Learning. PMLR, 2022.[<span class="p">期刊</span>]</p><p class="s9" style="padding-left: 59pt;text-indent: -40pt;line-height: 154%;text-align: justify;"><span class="s80">[44] </span>Ruixue Liu, Baoyang Chen, Xiaoyu Guo, Yan Dai, Meng Chen, Zhijie Qiu, and Xiaodong He. From Knowledge Map to Mind Map: Artificial Imagination. Proceedings of the Second International Conference on Multimedia Information Processing and Retrieval (MIPR), pages 496–501, 2019. [<span class="p">会议录</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">[45] <span class="s9">Ruixue Liu, Baoyang Chen, Meng Chen, Youzheng Wu, Zhijie</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 154%;text-align: justify;">Qiu, and Xiaodong He. Mappa Mundi: An Interactive Artistic Mind Map Generator with Artificial Imagination. Proceedings of The 28th International Joint Conference on Artificial Intelligence (IJCAI), 2019. [<span class="p">会议录</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">[46] <span class="s9">Ruixue Liu, Baoyang Chen, Xiaoyu Guo, Meng Chen, Zhijie Qiu,</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 153%;text-align: justify;">and Xiaodong He. Another AI? Artificial Imagination for Artistic Mind Map Generation. International Journal of Multimedia Data Engineering and Management (IJMDEM), Volume 10, Issue 3, Article 3, 2019. [<span class="p">期刊</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">[47] <span class="s9">Shaozu Yuan, Ruixue Liu, Meng Chen, Baoyang Chen, Zhijie Qiu,</span></p><p class="s9" style="padding-top: 9pt;padding-left: 59pt;text-indent: 0pt;line-height: 153%;text-align: justify;">and Xiaodong He. Learning to Compose Stylistic Calligraphy Artwork with Emotions. MM &#39;21: Proceedings of the 29th ACM International Conference on Multimedia, pages 3701–3709, 2021. https://doi.org/10.1145/3474085.3475711. [<span class="p">会议录</span>]</p><p class="s80" style="padding-left: 18pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">[48] <span class="s9">Shaozu Yuan, Aijun Dai, Zhiling Yan, Ruixue Liu, Meng Chen,</span></p><p class="s9" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;line-height: 155%;text-align: justify;">Baoyang Chen, Zhijie Qiu, and Xiaodong He. Learning to Generate Poetic Chinese Landscape Painting with Calligraphy. Proceedings of the Thirty-First International Joint Conference on</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s9" style="padding-top: 4pt;padding-left: 59pt;text-indent: 0pt;line-height: 145%;text-align: justify;">Artificial Intelligence (IJCAI), AI and Arts - Exhibits, pages 5019-5022, 2022. https://doi.org/10.24963/ijcai.2022/696. [<span class="p">会议录</span>]</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part57.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
