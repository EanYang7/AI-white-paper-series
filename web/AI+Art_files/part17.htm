<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>2.4.2 生成式技术发展综述</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part16.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a><span> | </span><a href="part18.htm">下一个 &gt;</a></p><h4 style="padding-left: 10pt;text-indent: 0pt;text-align: left;"><a name="bookmark40">2.4.2 </a><span class="s17">生成式技术发展综述</span><a name="bookmark88">&zwnj;</a></h4><p style="padding-top: 7pt;padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: justify;">生成式技术在<span class="s9">AIGC </span>领域中也扮演着重要角色，它在数据生成和增强、无监督学习、视觉和语言生成、强化学习和策略生成，以及创意和艺术生成等方面为我们开启了创造性和多样性的视角，推动了智能系统在创造、理解和交互方面的进步。生成式技术通过学习数据分布模型来生成新的数据样本。这些模型通常基于概率模型，如生成对抗网络和变分自编码器。其中，生成对抗网络在图像生成领域取得了重大突破，其用于生成逼真的图像样本。后来，<span class="s9">Tero Karras </span>等人提出 <a href="part17.htm#bookmark90" class="s5">StyleGAN</a><span style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; vertical-align: 4pt;">11</span>，用于生成逼真的人脸图像。它通过在生成网络中引入风</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s23" style="padding-top: 4pt;padding-left: 10pt;text-indent: 18pt;line-height: 242%;text-align: left;"><a name="bookmark89">10      </a><span class="s21">Karras T, Laine S, Aila T. A style-based generator architecture for generative adversarial networks[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019: 4401-4410.</span></p><p class="s23" style="padding-left: 10pt;text-indent: 18pt;line-height: 242%;text-align: left;"><a name="bookmark90">11 </a><span class="s21">Karras T, Laine S, Aila T. A style-based generator architecture for generative adversarial networks[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019: 4401-4410.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;line-height: 139%;text-align: justify;">格向量，并采用渐变叠加的训练方法，生成高分辨率、多样化和具有艺术风格的人脸图像。人脸中的“<span class="s9">Style</span>”通常是指头部的姿态、面部的表情、人物的发型等。如图 <span class="s9">3-2 </span>所示，<span class="s9">StyleGAN </span>生成的人脸可以捕获到这些细节并生成高质量的图像，而且在不同分别率的条件下有一致的表现。<span class="s9">OpenAI </span>团队提出的 <span class="s9">GPT </span>基于深度自回归 <span class="s9">Transformer</span>模型。它在自然语言处理任务中取得了突破性的成果，具有强大的语言生成能力和广泛的应用前景。最近，<a href="part18.htm#bookmark92" class="s5">Stable Diffusion</a><span style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; vertical-align: 4pt;">12</span>作为一种生成式技术，提供了一种有效的方法来生成高质量的图像样本。该方法通过对噪声进行多步扩散来生成图像，每一步都会逐渐减小噪声的规模，使生成的图像逐渐变得清晰。<span class="s9">Stable Diffusion </span>在生成图像的质量和多样性方面取得了显著的进展，并被广泛应用于图像生成任务。</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part16.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a><span> | </span><a href="part18.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
