<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>3.真实感交通流仿真</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part22.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a><span> | </span><a href="part24.htm">下一个 &gt;</a></p><h4 style="padding-left: 38pt;text-indent: 0pt;text-align: left;">3.<span class="s2">真实感交通流仿真</span></h4><p class="s9" style="padding-top: 7pt;padding-left: 10pt;text-indent: 27pt;line-height: 139%;text-align: left;">NeRF <span class="p">也可用于从真实的场景视频中构建虚拟世界。从技术方面而言，挑战在于需要能够预先解耦开静态场景与动态物体。在一些特定的场景中，进行动静态分割是一件比较容易的事情，例如驾驶场景。故可以解耦开两者分别使用</span>NeRF <span class="p">进行建模渲染，而后再行融合，达到对虚拟世界可控编辑的目的。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 79pt;text-indent: 0pt;text-align: left;"><span><img width="376" height="208" alt="image" src="Image_082.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 78pt;text-indent: 0pt;text-align: left;"><span><img width="374" height="210" alt="image" src="Image_083.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s15" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: center;">图 <span class="s16">2-13</span>、图 <span class="s16">2-14</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part22.htm">&lt; 上一个</a><span> | </span><a href="../AI%2BArt.html">内容</a><span> | </span><a href="part24.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
